{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = '.'\n",
    "DIR_INPUT = os.path.join(DIR_DATA, 'input')\n",
    "DIR_OUTPUT = os.path.join(DIR_DATA, 'output')\n",
    "LABELS_FILE = os.path.join(DIR_OUTPUT, 'groundtruth.txt')\n",
    "\n",
    "OBJECT_LABELS = {\n",
    "    'hand': (0, 'hand')\n",
    "}\n",
    "NUM_OBJECTS = 1\n",
    "DIM_OUTPUT_PER_GRID_PER_ANCHOR = 5 + NUM_OBJECTS\n",
    "\n",
    "# Reference: https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg#L242 \n",
    "GRID_H, GRID_W = 13, 13 \n",
    "GRID_SIZE = 416//GRID_H\n",
    "ANCHORS = np.array(\n",
    "    [\n",
    "        [0.09112895, 0.06958421],\n",
    "        [0.21102316, 0.16803947],\n",
    "        [0.42625895, 0.26609842],\n",
    "        [0.25476474, 0.49848   ],\n",
    "        [0.52668947, 0.59138947]\n",
    "    ]\n",
    ")\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "ANCHORS *= np.array([GRID_H, GRID_W])  # map from [0,1] space to [0,19] space\n",
    "IMG_OUT_H, IMG_OUT_W = GRID_H * GRID_SIZE, GRID_W * GRID_SIZE \n",
    "\n",
    "DIR_TFRECORDS = 'data_hand_tfrecords'\n",
    "NUM_EXAMPLES_PER_TFRECORD = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(img, target):\n",
    "    # resize input\n",
    "    img_in_h = img.shape[0]\n",
    "    img_in_w = img.shape[1]\n",
    "    img = cv2.resize(img, (IMG_OUT_W, IMG_OUT_H))\n",
    "    \n",
    "    # get corners\n",
    "    y_min = target[1]\n",
    "    x_min = target[0]\n",
    "    y_max = target[5]\n",
    "    x_max = target[4]\n",
    "    \n",
    "    # convert from corner coordinates to x_center, y_center, width, height\n",
    "    y_center, x_center = (y_min + y_max)/2., (x_min + x_max)/2.\n",
    "    bbox_h, bbox_w = y_max - y_min, x_max - x_min\n",
    "\n",
    "    # normalize these values s.t. image goes from 0 to 1 (helps for arbitary size image size)\n",
    "    y_center /= img_in_h\n",
    "    x_center /= img_in_w\n",
    "    bbox_h /= img_in_h\n",
    "    bbox_w /= img_in_w\n",
    "    \n",
    "    class_idx = int(OBJECT_LABELS['hand'][0])\n",
    "    target_normalized = np.array([y_center, x_center, bbox_h, bbox_w, class_idx], dtype=np.float32) \n",
    "    \n",
    "    \n",
    "    return img, target_normalized\n",
    "\n",
    "def get_iou(hw1, hw2):\n",
    "    # hw: (height, width)\n",
    "    # assumption: both boxes have same centers\n",
    "    \n",
    "    # get extremes of both boxes\n",
    "    hw1_max, hw2_max = hw1/2., hw2/2.\n",
    "    hw1_min, hw2_min = -hw1_max, -hw2_max\n",
    "    \n",
    "    # get intersection area\n",
    "    intersection_min = np.maximum(hw1_min, hw2_min)\n",
    "    intersection_max = np.minimum(hw1_max, hw2_max)\n",
    "    hw_intersection = np.maximum(intersection_max-intersection_min, 0.)\n",
    "    area_intersection = hw_intersection[0] * hw_intersection[1]\n",
    "    \n",
    "    # get union area\n",
    "    area_hw1 = hw1[0] * hw1[1]\n",
    "    area_hw2 = hw2[0] * hw2[1]\n",
    "    area_union = area_hw1 + area_hw2 - area_intersection\n",
    "    \n",
    "    iou = area_intersection / area_union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def target2label(target):\n",
    "    # initialize return data\n",
    "    label = np.zeros((GRID_H, GRID_W, NUM_ANCHORS, 6), dtype=np.float32)  # 6: [offset_y, offset_x, scale_h, scale_w, class_idx, prob_obj]\n",
    "    \n",
    "    \n",
    "    target_class = target[4]\n",
    "\n",
    "    # map bbox from [0,1] space to [0,19] space\n",
    "    bbox = target[0:4] * np.array([GRID_H, GRID_W, GRID_H, GRID_W])\n",
    "\n",
    "    # get grid index for bbox center\n",
    "    idx_y = int(floor(bbox[0]))\n",
    "    idx_x = int(floor(bbox[1]))\n",
    "\n",
    "    # find best anchor corresponding to bbox\n",
    "    iou_best, idx_anchor_best = 0., 0\n",
    "    for idx_anchor, anchor in enumerate(ANCHORS):\n",
    "        iou = get_iou(bbox[2:4], anchor)\n",
    "        if iou > iou_best:\n",
    "            iou_best = iou\n",
    "            idx_anchor_best = idx_anchor\n",
    "\n",
    "    # update label\n",
    "    if iou_best > 0.:\n",
    "        label[idx_y, idx_x, idx_anchor_best] = np.array(\n",
    "            [\n",
    "                bbox[0] - idx_y,  # offset of box_center from top-left corner of grid containing box_center\n",
    "                bbox[1] - idx_x,\n",
    "                bbox[2]/ANCHORS[idx_anchor_best,0], # scale of anchor box so as to fit the bbox\n",
    "                bbox[3]/ANCHORS[idx_anchor_best,1],\n",
    "                target_class,\n",
    "                1.0  # prob_object (object is present with prob=1)\n",
    "            ], dtype=np.float32\n",
    "        )\n",
    "    return label\n",
    "        \n",
    "def get_processed_data(img, target):\n",
    "    # normalize input and output\n",
    "    img, target = normalize_data(img, target)\n",
    "    # target.shape = (1, 5)\n",
    "    # 5 corresponds to (c_y, c_x, h, w, class_label)\n",
    "    \n",
    "    label = target2label(target)\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to TFRecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion functions (data to feature data types)\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def write_example_to_TFRecord(img, target, writer):\n",
    "    # get processed data\n",
    "    img, label = get_processed_data(img, target)\n",
    "    \n",
    "    # create example from this data\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'img': _bytes_feature(img.tostring()),\n",
    "                'label': _bytes_feature(label.tostring()) \n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "def write_data_to_TFRecord():        \n",
    "    # read filenames\n",
    "    filenames = sorted(os.listdir(DIR_INPUT))\n",
    "    \n",
    "    # read targets\n",
    "    targets = np.loadtxt(LABELS_FILE, delimiter=',').astype(np.float32)\n",
    "    \n",
    "    # write data into multiple TFRecord files\n",
    "    idx_tfrecord, idx_data = 0, 0\n",
    "    if not os.path.exists(DIR_TFRECORDS):\n",
    "        os.makedirs(DIR_TFRECORDS)\n",
    "    \n",
    "    while idx_data < len(filenames):\n",
    "        # new TFRecord file\n",
    "        filename_tfrecord = os.path.join(DIR_TFRECORDS, str(idx_tfrecord) + '.tfrecords')\n",
    "        with tf.python_io.TFRecordWriter(filename_tfrecord) as writer:\n",
    "            # write examples into this file until limit is reached\n",
    "            idx_example = 0\n",
    "            while idx_data < len(filenames) and idx_example < NUM_EXAMPLES_PER_TFRECORD:\n",
    "                path = os.path.join(DIR_INPUT, filenames[idx_data])\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                target = targets[idx_data]\n",
    "                write_example_to_TFRecord(img, target, writer)\n",
    "                idx_data += 1\n",
    "                idx_example += 1\n",
    "            idx_tfrecord += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = write_data_to_TFRecord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
