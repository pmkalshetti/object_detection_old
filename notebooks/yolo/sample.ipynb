{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "DIR_DATA = 'data_VOC2012/VOC2012'\n",
    "DIR_INPUT = os.path.join(DIR_DATA, 'JPEGImages')\n",
    "DIR_OUTPUT = os.path.join(DIR_DATA, 'Annotations')\n",
    "\n",
    "OBJECT_LABELS = {\n",
    "    'tvmonitor': (0, 'Indoor'),\n",
    "    'aeroplane': (1, 'Vehicle'),\n",
    "    'bicycle': (2, 'Vehicle'),\n",
    "    'bird': (3, 'Animal'),\n",
    "    'boat': (4, 'Vehicle'),\n",
    "    'bottle': (5, 'Indoor'),\n",
    "    'bus': (6, 'Vehicle'),\n",
    "    'car': (7, 'Vehicle'),\n",
    "    'cat': (8, 'Animal'),\n",
    "    'chair': (9, 'Indoor'),\n",
    "    'cow': (10, 'Animal'),\n",
    "    'diningtable': (11, 'Indoor'),\n",
    "    'dog': (12, 'Animal'),\n",
    "    'horse': (13, 'Animal'),\n",
    "    'motorbike': (14, 'Vehicle'),\n",
    "    'person': (15, 'Person'),\n",
    "    'pottedplant': (16, 'Indoor'),\n",
    "    'sheep': (17, 'Animal'),\n",
    "    'sofa': (18, 'Indoor'),\n",
    "    'train': (19, 'Vehicle')\n",
    "}\n",
    "OBJECTS = ['tvmonitor', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', \n",
    "          'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train']\n",
    "\n",
    "NUM_OBJECTS = 20\n",
    "MAX_DETECTIONS_PER_IMAGE = 10\n",
    "IMG_OUT_H, IMG_OUT_W = 416, 416\n",
    "GRID_H, GRID_W = 13, 13\n",
    "GRID_SIZE = 416//GRID_H \n",
    "ANCHORS_NORMALIZED = np.array(\n",
    "    [\n",
    "        [0.05210654, 0.04405615],\n",
    "        [0.15865615, 0.14418923],\n",
    "        [0.42110308, 0.25680231],\n",
    "        [0.27136769, 0.60637077],\n",
    "        [0.70525231, 0.75157846]\n",
    "    ]\n",
    ")\n",
    "ANCHORS = ANCHORS_NORMALIZED * np.array([GRID_H, GRID_W])\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "THRESHOLD_OUT_PROB = 0.6\n",
    "THRESHOLD_IOU_NMS = 0.5\n",
    "\n",
    "CHECKPOINT_DIR = 'model'\n",
    "\n",
    "if tfe.num_gpus() > 0:\n",
    "    DEVICE = '/gpu:0'\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    DEVICE = '/cpu:0'\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(predictions):\n",
    "    predictions_yx = tf.sigmoid(predictions[..., 0:2])\n",
    "    predictions_hw = tf.exp(predictions[...,2:4])\n",
    "    predictions_prob_obj = tf.sigmoid(predictions[...,4:5])\n",
    "    predictions_prob_class = tf.nn.softmax(predictions[...,5:])\n",
    "    \n",
    "    return predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class\n",
    "\n",
    "def get_coordinates(h, w):\n",
    "    coordinates_y = tf.range(h)\n",
    "    coordinates_x = tf.range(w)\n",
    "    x, y = tf.meshgrid(coordinates_x, coordinates_y)\n",
    "    coordinates = tf.stack([y, x], axis=-1)\n",
    "    coordinates = tf.reshape(coordinates, [1, h, w, 1, 2])\n",
    "    coordinates = tf.cast(coordinates, tf.float32)\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "def grid2normalized(predictions_yx, predictions_hw):    \n",
    "    # create cartesian coordinates on grid space\n",
    "    coordinates = get_coordinates(GRID_H, GRID_W)\n",
    "    \n",
    "    # map from grid space to [0,19] space\n",
    "    anchors = tf.cast(tf.reshape(ANCHORS, [1, 1, 1, ANCHORS.shape[0], 2]), dtype=tf.float32)  # [0,19] space\n",
    "    predictions_yx += coordinates\n",
    "    predictions_hw *= anchors\n",
    "    \n",
    "    # map from [0,19] space to [0,1] space\n",
    "    shape = tf.cast(tf.reshape([GRID_H, GRID_W], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    predictions_yx /= shape\n",
    "    predictions_hw /= shape\n",
    "    \n",
    "    return predictions_yx, predictions_hw\n",
    "\n",
    "def center2corner(predictions_yx, predictions_hw):\n",
    "    # predictions_yx = [GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    \n",
    "    bbox_min = predictions_yx - (predictions_hw/2.)\n",
    "    bbox_max = predictions_yx + (predictions_hw/2.)\n",
    "    \n",
    "    predictions_corner = tf.concat([bbox_min[...,0:1], bbox_min[...,1:2], bbox_max[...,0:1], bbox_max[...,1:2]], axis=-1)\n",
    "    \n",
    "    return predictions_corner\n",
    "\n",
    "def get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class):\n",
    "    # compute overall prob for each anchor in each grid\n",
    "    predictions_prob = predictions_prob_obj * predictions_prob_class\n",
    "    \n",
    "    # get max prob among all classes at each anchor in each grid\n",
    "    predictions_idx_class_max = tf.argmax(predictions_prob, axis=-1)\n",
    "    predictions_prob = tf.reduce_max(predictions_prob, axis=-1)\n",
    "    \n",
    "    # compute filter mask\n",
    "    mask_filter = predictions_prob >= THRESHOLD_OUT_PROB\n",
    "    \n",
    "    # apply mask on output\n",
    "    bbox_filtered = tf.boolean_mask(predictions_corner, mask_filter)\n",
    "    prob_filtered = tf.boolean_mask(predictions_prob, mask_filter)\n",
    "    with tf.device('/cpu:0'):\n",
    "        idx_class_filtered = tf.boolean_mask(predictions_idx_class_max, mask_filter)\n",
    "    \n",
    "    if DEVICE == '/gpu:0':\n",
    "        idx_class_filtered = idx_class_filtered.gpu()        \n",
    "    \n",
    "    return bbox_filtered, prob_filtered, idx_class_filtered\n",
    "\n",
    "\n",
    "def predictions2outputs(predictions):\n",
    "    # apply corresponding transformations on predictions\n",
    "    predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class = apply_transformations(predictions)\n",
    "    \n",
    "    # map predictions_bbox to [0,1] space\n",
    "    predictions_yx, predictions_hw = grid2normalized(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # represent boxes using corners\n",
    "    predictions_corner = center2corner(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # filter predictions based on (prob_obj * prob_class). (needs to be done separately for each image in batch)\n",
    "    bbox_filtered, prob_filtered, idx_class_filtered = get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class)\n",
    "    # bbox_filtered.shape = [BATCH_SIZE, NUM_FILTERED, 4]\n",
    "    \n",
    "    # TODO: perform nms for each class separately\n",
    "    # scale boxes from [0,1] to image space\n",
    "    img_space = tf.reshape(tf.cast(tf.stack([IMG_OUT_H, IMG_OUT_W, IMG_OUT_H, IMG_OUT_W]), tf.float32), [1, 1, 4])\n",
    "    bbox_filtered = tf.reshape(bbox_filtered*img_space, [-1, 4])  # tf.nms takes num_boxes (no batch support)\n",
    "    \n",
    "    # perform non-max suppression\n",
    "    with tf.device('/cpu:0'):\n",
    "        bbox_nms_indices = tf.image.non_max_suppression(bbox_filtered, tf.reshape(prob_filtered,[-1]), MAX_DETECTIONS_PER_IMAGE, THRESHOLD_IOU_NMS)\n",
    "    if DEVICE == '/gpu:0':\n",
    "        bbox_nms_indices = bbox_nms_indices.gpu()\n",
    "    \n",
    "    bbox_nms = tf.gather(bbox_filtered, bbox_nms_indices)  # box_nms.shape = [len(bbox_nms_indices), 4]\n",
    "    prob_nms = tf.expand_dims(tf.gather(prob_filtered, bbox_nms_indices), axis=-1) # prob_nms.shape = [len(bbox_nms_indices), 1]\n",
    "    with tf.device('/cpu:0'):\n",
    "        idx_class_nms = tf.expand_dims(tf.cast(tf.gather(idx_class_filtered, bbox_nms_indices), tf.float32), axis=-1)\n",
    "    if DEVICE == '/gpu:0':\n",
    "        idx_class_nms = idx_class_nms.gpu()\n",
    "    \n",
    "    # concat return data\n",
    "    output = tf.concat([bbox_nms, prob_nms, idx_class_nms], axis=-1)\n",
    "\n",
    "    return tf.expand_dims(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "        \n",
    "        # add layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, padding='same', use_bias=False)\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, padding='same', use_bias=False)\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, padding='same', use_bias=False)\n",
    "        self.norm3 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv4 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False)\n",
    "        self.norm4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv2D(128, 3, padding='same', use_bias=False)\n",
    "        self.norm5 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool5 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv6 = tf.keras.layers.Conv2D(256, 3, padding='same', use_bias=False)\n",
    "        self.norm6 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv7 = tf.keras.layers.Conv2D(128, 1, padding='same', use_bias=False)\n",
    "        self.norm7 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv8 = tf.keras.layers.Conv2D(256, 3, padding='same', use_bias=False)\n",
    "        self.norm8 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool8 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv9 = tf.keras.layers.Conv2D(512, 3, padding='same', use_bias=False)\n",
    "        self.norm9 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv10 = tf.keras.layers.Conv2D(256, 1, padding='same', use_bias=False)\n",
    "        self.norm10 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv11 = tf.keras.layers.Conv2D(512, 3, padding='same', use_bias=False)\n",
    "        self.norm11 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv12 = tf.keras.layers.Conv2D(256, 1, padding='same', use_bias=False)\n",
    "        self.norm12 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv13 = tf.keras.layers.Conv2D(512, 3, padding='same', use_bias=False)\n",
    "        self.norm13 = tf.keras.layers.BatchNormalization()  # skip after this\n",
    "        self.pool13 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv14 = tf.keras.layers.Conv2D(1024, 3, padding='same', use_bias=False)\n",
    "        self.norm14 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv15 = tf.keras.layers.Conv2D(512, 1, padding='same', use_bias=False)\n",
    "        self.norm15 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv16 = tf.keras.layers.Conv2D(1024, 3, padding='same', use_bias=False)\n",
    "        self.norm16 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv17 = tf.keras.layers.Conv2D(512, 1, padding='same', use_bias=False)\n",
    "        self.norm17 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv18 = tf.keras.layers.Conv2D(1024, 3, padding='same', use_bias=False)\n",
    "        self.norm18 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv19 = tf.keras.layers.Conv2D(1024, 3, padding='same', use_bias=False)\n",
    "        self.norm19 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv20 = tf.keras.layers.Conv2D(1024, 3, padding='same', use_bias=False)\n",
    "        self.norm20 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv21 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False)  # apply on skipped connection\n",
    "        self.norm21 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv22 = tf.keras.layers.Conv2D(1024, 3, padding='same', use_bias=False)\n",
    "        self.norm22 = tf.keras.layers.BatchNormalization()\n",
    "        # Feature Extractor Ends Here!\n",
    "        \n",
    "        # Detector Layer!\n",
    "        self.conv23 = tf.keras.layers.Conv2D(NUM_ANCHORS*(4+1+NUM_OBJECTS), 1, padding='same')\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        # imgs.shape = [B, IMG_H, IMG_W, 3]\n",
    "        \n",
    "        # for now, resize and reshape imgs to vector\n",
    "        imgs = tf.image.resize_images(imgs, [416, 416])\n",
    "        \n",
    "        x = self.conv1(imgs)\n",
    "        x = self.norm1(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.norm4(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.norm5(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        x = self.conv6(x)\n",
    "        x = self.norm6(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv7(x)\n",
    "        x = self.norm7(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv8(x)\n",
    "        x = self.norm8(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        x = self.pool8(x)\n",
    "        \n",
    "        x = self.conv9(x)\n",
    "        x = self.norm9(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv10(x)\n",
    "        x = self.norm10(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv11(x)\n",
    "        x = self.norm11(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv12(x)\n",
    "        x = self.norm12(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv13(x)\n",
    "        x = self.norm13(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        x_skip = tf.identity(x)\n",
    "        x = self.pool13(x)\n",
    "        \n",
    "        x = self.conv14(x)\n",
    "        x = self.norm14(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv15(x)\n",
    "        x = self.norm15(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv16(x)\n",
    "        x = self.norm16(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv17(x)\n",
    "        x = self.norm17(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv18(x)\n",
    "        x = self.norm18(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv19(x)\n",
    "        x = self.norm19(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x = self.conv20(x)\n",
    "        x = self.norm20(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        \n",
    "        x_skip = self.conv21(x_skip)\n",
    "        x_skip = self.norm21(x_skip)\n",
    "        x_skip = tf.nn.leaky_relu(x_skip, alpha=0.1)\n",
    "        x_skip = tf.space_to_depth(x_skip, block_size=2)  # lossless shrinkage of feature map\n",
    "        \n",
    "        x = tf.concat([x_skip, x], axis=-1)  # low_level features concatenated with high_level features\n",
    "        \n",
    "        x = self.conv22(x)\n",
    "        x = self.norm22(x)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "        # Feature Extractor ends here!\n",
    "        \n",
    "        # Detector layer\n",
    "        x = self.conv23(x)\n",
    "        \n",
    "        # reshape output\n",
    "        pred = tf.reshape(x, [-1, GRID_H, GRID_W, NUM_ANCHORS, 4+1+NUM_OBJECTS])\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def predict(self, imgs):\n",
    "        '''predicts bboxes and draws them on the image'''\n",
    "        # imgs.shape = [B, IMG_H, IMG_W, 3]\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = self.forward(imgs)\n",
    "        \n",
    "        predictions = tf.concat([predictions[...,1::-1], predictions[...,3:1:-1], predictions[...,4:]], axis=-1)\n",
    "        \n",
    "        # post-process to get bounding boxes\n",
    "        outputs = predictions2outputs(predictions)  \n",
    "        # CAUTION!!!\n",
    "        # TODO: use batch multi-class nms (currently works with BATCH_SIZE=1)\n",
    "        # reference: https://github.com/tensorflow/models/blob/master/research/object_detection/core/post_processing.py\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    # read and process image\n",
    "    img_name = os.path.join(DIR_INPUT, filename + '.jpg')\n",
    "    img = cv2.imread(img_name)\n",
    "    img_in_h = img.shape[0]\n",
    "    img_in_w = img.shape[1]\n",
    "    img = cv2.resize(img, (IMG_OUT_W, IMG_OUT_H))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    # read annotation\n",
    "    annotation_name = os.path.join(DIR_OUTPUT, filename + '.xml')\n",
    "    tree = ET.parse(annotation_name)\n",
    "    root = tree.getroot()\n",
    "    targets = []\n",
    "    for obj in root.findall('object'):\n",
    "        # read class label\n",
    "        label_text = obj.find('name').text\n",
    "        label = int(OBJECT_LABELS[label_text][0])\n",
    "        \n",
    "        # read bbox\n",
    "        bbox = obj.find('bndbox')\n",
    "        y_min = float(bbox.find('ymin').text)\n",
    "        x_min = float(bbox.find('xmin').text)\n",
    "        y_max = float(bbox.find('ymax').text)\n",
    "        x_max = float(bbox.find('xmax').text)\n",
    "        \n",
    "        # normalize these values s.t. image goes from 0 to 1 (helps for arbitary size image size)\n",
    "        y_min /= img_in_h\n",
    "        x_min /= img_in_w\n",
    "        y_max /= img_in_h\n",
    "        x_max /= img_in_w\n",
    "        \n",
    "        # map from [0,1] to image space\n",
    "        y_min *= IMG_OUT_H\n",
    "        x_min *= IMG_OUT_W\n",
    "        y_max *= IMG_OUT_H\n",
    "        x_max *= IMG_OUT_W\n",
    "\n",
    "        targets.append((y_min, x_min, y_max, x_max, 1, label))\n",
    "        \n",
    "    return img, np.array(targets, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_W, IMG_H))\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def draw_output(img, output):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    output = output.astype(np.int32)\n",
    "    for idx_box in range(output.shape[0]):\n",
    "        bbox = output[idx_box]\n",
    "        img = cv2.rectangle(img, (bbox[1], bbox[0]), (bbox[3], bbox[2]), color=(255, 0, 0), thickness=3)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read filenames\n",
    "filenames = sorted(os.listdir(DIR_INPUT))\n",
    "filenames = [filename[:-4] for filename in filenames]  # trim extension\n",
    "\n",
    "# load model\n",
    "with tf.device(DEVICE):\n",
    "    model = Model()\n",
    "    checkpoint = tfe.Checkpoint(model=model, optimizer_step=tf.train.get_or_create_global_step())\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_output(img, output):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    for idx_box in range(output.shape[0]):\n",
    "        conf = output[idx_box][4]\n",
    "        bbox = output[idx_box].astype(np.int32)\n",
    "        obj_class = OBJECTS[bbox[5]]\n",
    "        img = cv2.rectangle(img, (bbox[1], bbox[0]), (bbox[3], bbox[2]), color=(255, 0, 0), thickness=3)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        img = cv2.putText(img, '{}({:.2f})'.format(obj_class, conf),(bbox[1], bbox[0]), font, .5,(0,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on each data and store gt and pred\n",
    "with open(DIR_DATA+'/gt_file.txt', 'w') as gt_file, open(DIR_DATA+'/pred_file.txt', 'w') as pred_file :\n",
    "    for filename in filenames:\n",
    "        # read data\n",
    "        img, gt = read_data(filename)\n",
    "\n",
    "        # predict on image\n",
    "        output = model.predict(img)\n",
    "\n",
    "        # write pred and gt to file (gt.shape = [num_objects, 6], pred.shape = [MAX_DETECTIONS_PER_IMAGE, 6])\n",
    "        pred = output[0].numpy()\n",
    "\n",
    "        gt_file.write( ' '.join([str(y) for y in gt.flatten()]) + '\\n' )\n",
    "        pred_file.write( ' '.join([str(y) for y in pred.flatten()]) + '\\n' )\n",
    "\n",
    "    #     # draw output\n",
    "    #     img_out = draw_output(img[0], output[0].numpy())\n",
    "\n",
    "    #     # draw gt\n",
    "    #     img_gt = draw_output(img[0], gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
