{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TFRECORDS = 'data_small_tfrecords'\n",
    "DATA_TRAIN = glob('./'+DIR_TFRECORDS+'/*.tfrecords')\n",
    "\n",
    "NUM_OBJECTS = 20\n",
    "MAX_DETECTIONS_PER_IMAGE = 20\n",
    "\n",
    "GRID_H, GRID_W = 19, 19\n",
    "GRID_SIZE = 608//GRID_H \n",
    "\n",
    "ANCHORS_NORMALIZED = np.array(\n",
    "    [\n",
    "        [0.09112895, 0.06958421],\n",
    "        [0.21102316, 0.16803947],\n",
    "        [0.42625895, 0.26609842],\n",
    "        [0.25476474, 0.49848   ],\n",
    "        [0.52668947, 0.59138947]\n",
    "    ]\n",
    ")\n",
    "ANCHORS = ANCHORS_NORMALIZED * np.array([GRID_H, GRID_W])\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "\n",
    "IMG_H, IMG_W = GRID_H * GRID_SIZE, GRID_W * GRID_SIZE\n",
    "\n",
    "COOEFFICIENT_OBJ = 1\n",
    "COOEFFICIENT_NO_OBJ = 1\n",
    "COOEFFICIENT_REG = 5\n",
    "\n",
    "THRESHOLD_IOU_SCORES = 0.5\n",
    "COEFF_LOSS_CONFIDENCE_OBJECT_PRESENT = 5\n",
    "COEFF_LOSS_CONFIDENCE_OBJECT_ABSENT = 1\n",
    "THRESHOLD_OUT_PROB = 0.5\n",
    "THRESHOLD_IOU_NMS = 0.5\n",
    "\n",
    "NUM_EPOCHS = 10 # not used\n",
    "BATCH_SIZE = 5\n",
    "CHECKPOINT_DIR = 'model'\n",
    "CHECKPOINT_PREFIX = os.path.join(CHECKPOINT_DIR, \"ckpt\")\n",
    "DIR_IMG_OUT = 'imgs_out'\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def draw_adjusted_anchor(img, idx_h, idx_w, idx_a, label_bbox):\n",
    "    # box_adjustment.shape = [5,]\n",
    "    \n",
    "    center_y = (label_bbox[0]+idx_h)*GRID_SIZE\n",
    "    center_x = (label_bbox[1]+idx_w)*GRID_SIZE\n",
    "    \n",
    "    height = label_bbox[2] * ANCHORS[idx_a,0] * GRID_SIZE\n",
    "    width = label_bbox[3] * ANCHORS[idx_a,1] * GRID_SIZE\n",
    "     \n",
    "    left = int(center_x - width/2)\n",
    "    top = int(center_y - height/2)\n",
    "    right = int(left + width)\n",
    "    bottom = int(top + height)\n",
    "\n",
    "    img = cv2.rectangle(img, (left, top), (right, bottom), color=(0, 255, 0), thickness=3)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def label(img, label):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    for idx_h in range(GRID_H):\n",
    "        for idx_w in range(GRID_W):\n",
    "            for idx_a in range(NUM_ANCHORS):\n",
    "                if sigmoid(label[idx_h, idx_w, idx_a, 5]) > 0.1:\n",
    "                    bbox = label[idx_h, idx_w, idx_a, :4]\n",
    "                    img = draw_adjusted_anchor(img, idx_h, idx_w, idx_a, bbox)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def draw_output(img, output):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    output = output.astype(np.int32)\n",
    "    for idx_box in range(output.shape[0]):\n",
    "        bbox = output[idx_box]\n",
    "        img = cv2.rectangle(img, (bbox[1], bbox[0]), (bbox[3], bbox[2]), color=(255, 0, 0), thickness=3)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def center2corner(predictions_yx, predictions_hw):\n",
    "    # predictions_yx = [GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    \n",
    "    bbox_min = predictions_yx - (predictions_hw/2.)\n",
    "    bbox_max = predictions_yx + (predictions_hw/2.)\n",
    "    \n",
    "    predictions_corner = tf.concat([bbox_min[...,0:1], bbox_min[...,1:2], bbox_max[...,0:1], bbox_max[...,1:2]], axis=-1)\n",
    "    return predictions_corner\n",
    "\n",
    "def get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class):\n",
    "    # compute overall prob for each anchor in each grid\n",
    "    predictions_prob = predictions_prob_obj * predictions_prob_class\n",
    "    \n",
    "    # get max prob among all classes at each anchor in each grid\n",
    "    predictions_idx_class_max = tf.argmax(predictions_prob, axis=-1)\n",
    "    predictions_prob = tf.reduce_max(predictions_prob, axis=-1)\n",
    "    \n",
    "    # compute filter mask\n",
    "    mask_filter = predictions_prob >= THRESHOLD_OUT_PROB\n",
    "    \n",
    "    # apply mask on output\n",
    "    bbox_filtered = tf.boolean_mask(predictions_corner, mask_filter)\n",
    "    prob_filtered = tf.boolean_mask(predictions_prob, mask_filter)\n",
    "    with tf.device('/cpu:0'):\n",
    "        idx_class_filtered = tf.boolean_mask(predictions_idx_class_max, mask_filter)\n",
    "    \n",
    "    return bbox_filtered, prob_filtered, idx_class_filtered\n",
    "\n",
    "\n",
    "def predictions2outputs(predictions):\n",
    "    # apply corresponding transformations on predictions\n",
    "    predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class = apply_transformations(predictions)\n",
    "    \n",
    "    # map predictions_bbox to [0,1] space\n",
    "    predictions_yx, predictions_hw = grid2normalized(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # represent boxes using corners\n",
    "    predictions_corner = center2corner(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # filter predictions based on (prob_obj * prob_class). (needs to be done separately for each image in batch)\n",
    "    bbox_filtered, prob_filtered, idx_class_filtered = get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class)\n",
    "#     bbox_filtered, prob_filtered = get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class)\n",
    "    # bbox_filtered.shape = [BATCH_SIZE, NUM_FILTERED, 4]\n",
    "    \n",
    "    # TODO: perform nms for each class separately\n",
    "    # scale boxes from [0,1] to image space\n",
    "    img_space = tf.reshape(tf.cast(tf.stack([IMG_H, IMG_W, IMG_H, IMG_W]), tf.float32), [1, 1, 4])\n",
    "    bbox_filtered = tf.reshape(bbox_filtered, [-1, 4])  # tf.nms takes num_boxes (no batch support)\n",
    "    \n",
    "    # perform non-max suppression\n",
    "    with tf.device('/cpu:0'):\n",
    "        bbox_nms_indices = tf.image.non_max_suppression(bbox_filtered, tf.reshape(prob_filtered,[-1]), MAX_DETECTIONS_PER_IMAGE)\n",
    "    bbox_nms = tf.gather(bbox_filtered, bbox_nms_indices)  # box_nms.shape = [len(bbox_nms_indices), 4]\n",
    "    prob_nms = tf.expand_dims(tf.gather(prob_filtered, bbox_nms_indices), axis=-1) # prob_nms.shape = [len(bbox_nms_indices), 1]\n",
    "    with tf.device('/cpu:0'):\n",
    "        idx_class_nms = tf.expand_dims(tf.cast(tf.gather(idx_class_filtered, bbox_nms_indices), tf.float32), axis=-1)\n",
    "    \n",
    "    # concat return data\n",
    "    output = tf.concat([bbox_nms, prob_nms, idx_class_nms], axis=-1)\n",
    "#     output = tf.concat([bbox_nms, prob_nms], axis=-1)\n",
    "    \n",
    "    return tf.expand_dims(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    # dictionary as per saved TFRecord\n",
    "    keys_to_features = {\n",
    "        'img': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'label': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "    }\n",
    "\n",
    "    # parse record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    # decode image\n",
    "    img = tf.decode_raw(parsed['img'], tf.uint8)\n",
    "    img = tf.cast(tf.reshape(img, [IMG_H, IMG_W, 3]), tf.float32)\n",
    "    img /= 255.  # normalize\n",
    "\n",
    "    # decode label\n",
    "    label = tf.decode_raw(parsed['label'], tf.float32)\n",
    "    label = tf.reshape(label, [GRID_H, GRID_W, NUM_ANCHORS, 6])\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(predictions):\n",
    "    predictions_yx = tf.sigmoid(predictions[..., 0:2])\n",
    "    predictions_hw = tf.exp(predictions[...,2:4])\n",
    "    predictions_prob_obj = tf.sigmoid(predictions[...,4:5])\n",
    "    predictions_prob_class = tf.nn.softmax(predictions[...,5:])\n",
    "    \n",
    "    return predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class\n",
    "\n",
    "def get_coordinates(h, w):\n",
    "    coordinates_y = tf.range(h)\n",
    "    coordinates_x = tf.range(w)\n",
    "    x, y = tf.meshgrid(coordinates_x, coordinates_y)\n",
    "    coordinates = tf.stack([y,x], axis=-1)\n",
    "    coordinates = tf.reshape(coordinates, [1, h, w, 1, 2])\n",
    "    coordinates = tf.cast(coordinates, tf.float32)\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "def grid2normalized(predictions_yx, predictions_hw):    \n",
    "    # create cartesian coordinates on grid space\n",
    "    coordinates = get_coordinates(GRID_H, GRID_W)\n",
    "    \n",
    "    # map from grid space to [0,19] space\n",
    "    anchors = tf.cast(tf.reshape(ANCHORS, [1, 1, 1, ANCHORS.shape[0], 2]), dtype=tf.float32)  # [0,19] space\n",
    "    predictions_yx += coordinates\n",
    "    predictions_hw *= anchors\n",
    "    \n",
    "    # map from [0,19] space to [0,1] space\n",
    "    shape = tf.cast(tf.reshape([GRID_H, GRID_W], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    predictions_yx /= shape\n",
    "    predictions_hw /= shape\n",
    "    \n",
    "    return predictions_yx, predictions_hw\n",
    "\n",
    "def get_boxes_gt(args_map):\n",
    "    # extract ground truth bboxes wherever prob_obj = 1\n",
    "    mask_object = tf.cast(tf.reshape(args_map[1], [GRID_H, GRID_W, NUM_ANCHORS]), tf.bool)\n",
    "    bboxes = tf.boolean_mask(args_map[0], mask_object)\n",
    "    # bboxes.shape = [NUM_DETECTIONS, 4]; NUM_DETECTIONS vary with each image\n",
    "    \n",
    "    # pad bboxes so that bboxes is fixed dimension (fix NUM_DETECTIONS to MAX_DETECTIONS_PER_IMAGE)\n",
    "    pad = tf.zeros((MAX_DETECTIONS_PER_IMAGE - tf.shape(bboxes)[0], 4))  # TODO: when NUM_DETECTIONS > MAX_DETECTIONS_PER_IMAGE\n",
    "    bboxes = tf.concat([bboxes, pad], axis=0)\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def get_iou_scores(predictions_yx, predictions_hw, bboxes_gt):\n",
    "    # predictions_yx.shape = predictions_hw.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    # bboxes_gt.shape = [BATCH_SIZE, MAX_DETECTIONS_PER_IMAGE, 4]\n",
    "    \n",
    "    # compute ious for each anchor in each grid in axis=4\n",
    "    predictions_yx = tf.expand_dims(predictions_yx, 4)\n",
    "    predictions_hw = tf.expand_dims(predictions_hw, 4)\n",
    "    \n",
    "    predictions_min = predictions_yx - predictions_hw/2.\n",
    "    predictions_max = predictions_yx + predictions_hw/2.\n",
    "    \n",
    "    bboxes_gt = tf.reshape(bboxes_gt, [tf.shape(bboxes_gt)[0], 1, 1, 1, MAX_DETECTIONS_PER_IMAGE, 4])\n",
    "    bboxes_gt_yx = bboxes_gt[..., 0:2]\n",
    "    bboxes_gt_hw = bboxes_gt[..., 2:4]\n",
    "    \n",
    "    bboxes_gt_min = bboxes_gt_yx - bboxes_gt_hw/2.\n",
    "    bboxes_gt_max = bboxes_gt_yx + bboxes_gt_hw/2.\n",
    "    \n",
    "    intersection_min = tf.maximum(predictions_min, bboxes_gt_min)\n",
    "    intersection_max = tf.minimum(predictions_max, bboxes_gt_max)\n",
    "    intersection_hw = tf.maximum(intersection_max - intersection_min, 0.)\n",
    "    area_intersection = intersection_hw[..., 0] * intersection_hw[..., 1]\n",
    "    \n",
    "    area_predictions = predictions_hw[...,0] * predictions_hw[...,1]\n",
    "    area_bboxes_gt = bboxes_gt_hw[...,0] * bboxes_gt_hw[...,1]\n",
    "    area_union = area_bboxes_gt + area_predictions - area_intersection\n",
    "    iou = area_intersection / area_union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def get_confidence_loss(labels_prob_obj, iou_mask, predictions_prob_obj):\n",
    "    mask_object_absent = (1 - labels_prob_obj) * (1 - iou_mask)\n",
    "    loss_object_absent = mask_object_absent * tf.square(predictions_prob_obj)\n",
    "    \n",
    "    loss_object_present = labels_prob_obj * tf.square(1-predictions_prob_obj)\n",
    "    \n",
    "    loss_confidence = COEFF_LOSS_CONFIDENCE_OBJECT_ABSENT * loss_object_absent \\\n",
    "            + COEFF_LOSS_CONFIDENCE_OBJECT_PRESENT * loss_object_present\n",
    "    \n",
    "    return tf.reduce_sum(loss_confidence)\n",
    "    \n",
    "def get_classification_loss(labels_prob_obj, labels_class, predictions_prob_class):\n",
    "    labels_class = tf.cast(labels_class, tf.int32)\n",
    "    labels_class = tf.one_hot(labels_class, NUM_OBJECTS)\n",
    "    \n",
    "    loss_classification = labels_prob_obj * tf.squared_difference(labels_class, predictions_prob_class)\n",
    "    \n",
    "    return tf.reduce_sum(loss_classification)\n",
    "\n",
    "def get_regression_loss(labels_bbox, predictions_bbox, labels_prob_obj):\n",
    "    loss_regression = labels_prob_obj * tf.squared_difference(labels_bbox,predictions_bbox)\n",
    "    \n",
    "    return tf.reduce_sum(loss_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "        \n",
    "        # add layers\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "#         self.dense3 = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
    "#         self.dense4 = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
    "#         self.dense5 = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
    "        self.dense6 = tf.keras.layers.Dense(GRID_H*GRID_W*NUM_ANCHORS*(5+NUM_OBJECTS))\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        # imgs.shape = [B, IMG_H, IMG_W, 3]\n",
    "        \n",
    "        # for now, resize and reshape imgs to vector\n",
    "        imgs = tf.image.resize_images(imgs, [64, 64])\n",
    "        imgs = tf.layers.flatten(imgs)\n",
    "        \n",
    "        d = self.dense1(imgs)\n",
    "        d = self.dense2(d)\n",
    "#         d = self.dense3(d)\n",
    "#         d = self.dense4(d)\n",
    "#         d = self.dense5(d)\n",
    "        d = self.dense6(d)\n",
    "        \n",
    "        # reshape output\n",
    "        pred = tf.reshape(d, [-1, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS])\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def get_loss(self, predictions, labels):\n",
    "        # predictions.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS] (they are in grid space)\n",
    "        # labels.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 6]\n",
    "\n",
    "        # apply corresponding transformations on predictions\n",
    "        predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class = apply_transformations(predictions)\n",
    "\n",
    "        # map predictions_bbox to [0,1] space\n",
    "        predictions_yx, predictions_hw = grid2normalized(predictions_yx, predictions_hw)\n",
    "\n",
    "        # map labels_bbox to [0,1] space\n",
    "        labels_yx, labels_hw = grid2normalized(labels[...,0:2], labels[...,2:4])\n",
    "\n",
    "        # get ground truth bboxes using labels_bbox & prob_obj in labels\n",
    "        labels_bbox = tf.concat([labels_yx, labels_hw], axis=-1)\n",
    "        bboxes_gt = tf.map_fn(get_boxes_gt, (labels_bbox, labels[...,5]), dtype=tf.float32)\n",
    "\n",
    "        # compute iou scores for each anchor in each grid for all bboxes_gt\n",
    "        iou_scores = get_iou_scores(predictions_yx, predictions_hw, bboxes_gt)\n",
    "\n",
    "        # keep anchors whose iou_scores are above THRESHOLD_IOU_SCORES\n",
    "        iou_scores_best = tf.reduce_max(iou_scores, axis=4, keep_dims=True)\n",
    "        iou_mask = tf.cast(iou_scores_best > THRESHOLD_IOU_SCORES, tf.float32)\n",
    "\n",
    "        ## Loss\n",
    "        # object confidence loss (presence and absence)\n",
    "        loss_confidence = get_confidence_loss(labels[...,5:6], iou_mask, predictions_prob_obj)\n",
    "\n",
    "        # classification loss\n",
    "        loss_classification = get_classification_loss(labels[...,5:6], labels[...,4], predictions_prob_class)\n",
    "\n",
    "        # regression loss\n",
    "        predictions_bbox = tf.concat([predictions_yx, predictions_hw], axis=-1)\n",
    "        loss_regression = get_regression_loss(labels_bbox, predictions_bbox, labels[...,5:6])\n",
    "\n",
    "        # total loss\n",
    "        loss = ( loss_confidence + loss_classification + loss_regression ) / tf.cast(tf.shape(labels)[0], tf.float32)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def train(self, dataset):\n",
    "        '''trains the model for one epoch'''\n",
    "        epoch_loss = tf.constant(0.)\n",
    "        for idx_batch, data in enumerate(tfe.Iterator(dataset)):\n",
    "            with tfe.GradientTape() as tape:\n",
    "                # forward pass\n",
    "                predictions = self.forward(data[0])\n",
    "\n",
    "                # compute loss\n",
    "                loss = self.get_loss(predictions, data[1])\n",
    "                \n",
    "            # backward pass (compute gradients)\n",
    "            gradients = tape.gradient(loss, self.variables)\n",
    "            \n",
    "            # update parameters\n",
    "            self.optimizer.apply_gradients(\n",
    "                zip(gradients, self.variables), \n",
    "                global_step=tf.train.get_or_create_global_step()\n",
    "            )\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            \n",
    "        return (epoch_loss/(idx_batch+1)).numpy()\n",
    "        \n",
    "    def predict(self, imgs):\n",
    "        '''predicts bboxes and draws them on the image'''\n",
    "        # imgs.shape = [B, IMG_H, IMG_W, 3]\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = self.forward(imgs)\n",
    "        \n",
    "        # post-process to get bounding boxes\n",
    "        outputs = predictions2outputs(predictions)  \n",
    "        # CAUTION!!!\n",
    "        # TODO: use batch multi-class nms (currently works with BATCH_SIZE=1)\n",
    "        # reference: https://github.com/tensorflow/models/blob/master/research/object_detection/core/post_processing.py\n",
    "        \n",
    "        # draw outputs on the image\n",
    "        with tf.device('/cpu:0'):\n",
    "            imgs_out = tf.image.draw_bounding_boxes(imgs, outputs[..., 0:4])\n",
    "        \n",
    "        return imgs_out, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset processing\n",
    "dataset_train = tf.data.TFRecordDataset(DATA_TRAIN)\n",
    "dataset_train = dataset_train.map(parse_record)\n",
    "dataset_train = dataset_train.shuffle(buffer_size=1024)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Loss=449.24560546875\n",
      "Epoch:1, Loss=443.33221435546875\n",
      "Epoch:2, Loss=432.46881103515625\n",
      "Epoch:3, Loss=414.12835693359375\n",
      "Epoch:4, Loss=386.5214538574219\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.optimizer = tf.train.AdamOptimizer(0.00001)\n",
    "    for i in range(5):\n",
    "        loss = model.train(dataset_train)\n",
    "        print('Epoch:{}, Loss={}'.format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/ckpt-1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tfe.Checkpoint(model=model, optimizer_step=tf.train.get_or_create_global_step())\n",
    "checkpoint.save(file_prefix=CHECKPOINT_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset processing\n",
    "dataset_test = tf.data.TFRecordDataset(DATA_TRAIN)\n",
    "dataset_test = dataset_test.map(parse_record)\n",
    "dataset_test = dataset_test.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    # load trained model\n",
    "    checkpoint = tfe.Checkpoint(model=model, optimizer_step=tf.train.get_or_create_global_step())\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_DIR))\n",
    "    \n",
    "    for idx_img, data in enumerate(tfe.Iterator(dataset_test)):\n",
    "        # predict\n",
    "        imgs_out, output = model.predict(data[0])\n",
    "        \n",
    "        # write images\n",
    "        img = imgs_out.numpy()[0]\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        cv2.imwrite(DIR_IMG_OUT+ '/'+str(idx_img)+'.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
