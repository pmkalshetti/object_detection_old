{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TFRECORDS = 'data_small_tfrecords'\n",
    "DATA_TRAIN = glob('./'+DIR_TFRECORDS+'/[0-9].tfrecords')\n",
    "\n",
    "NUM_OBJECTS = 20\n",
    "MAX_DETECTIONS_PER_IMAGE = 20\n",
    "\n",
    "GRID_SIZE = 608#32\n",
    "GRID_H, GRID_W = 1,1#19, 19\n",
    "\n",
    "ANCHORS_NORMALIZED = np.array(\n",
    "    [\n",
    "        [0.09112895, 0.06958421],\n",
    "        [0.21102316, 0.16803947],\n",
    "        [0.42625895, 0.26609842],\n",
    "        [0.25476474, 0.49848   ],\n",
    "        [0.52668947, 0.59138947]\n",
    "    ]\n",
    ")\n",
    "ANCHORS = ANCHORS_NORMALIZED * np.array([GRID_H, GRID_W])\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "\n",
    "IMG_H, IMG_W = 608, 608  # GRID_H * GRID_SIZE = 19 * 32 = 608\n",
    "\n",
    "COOEFFICIENT_OBJ = 1\n",
    "COOEFFICIENT_NO_OBJ = 1\n",
    "COOEFFICIENT_REG = 5\n",
    "\n",
    "THRESHOLD_IOU_SCORES = 0.5\n",
    "COEFF_LOSS_CONFIDENCE_OBJECT_PRESENT = 5\n",
    "COEFF_LOSS_CONFIDENCE_OBJECT_ABSENT = 1\n",
    "THRESHOLD_OUT_PROB = 0.5\n",
    "THRESHOLD_IOU_NMS = 0.5\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "MODEL_DIR = 'model'\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(predictions):\n",
    "    predictions_yx = tf.sigmoid(predictions[..., 0:2])\n",
    "    predictions_hw = tf.exp(predictions[...,2:4])\n",
    "    predictions_prob_obj = tf.sigmoid(predictions[...,4:5])\n",
    "    predictions_prob_class = tf.nn.softmax(predictions[...,5:])\n",
    "    \n",
    "    return predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class\n",
    "\n",
    "def get_coordinates(h, w):\n",
    "    coordinates_y = tf.range(h)\n",
    "    coordinates_x = tf.range(w)\n",
    "    x, y = tf.meshgrid(coordinates_x, coordinates_y)\n",
    "    coordinates = tf.stack([y,x], axis=-1)\n",
    "    coordinates = tf.reshape(coordinates, [1, h, w, 1, 2])\n",
    "    coordinates = tf.cast(coordinates, tf.float32)\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "def grid2normalized(predictions_yx, predictions_hw):    \n",
    "    # create cartesian coordinates on grid space\n",
    "    coordinates = get_coordinates(GRID_H, GRID_W)\n",
    "    \n",
    "    # map from grid space to [0,19] space\n",
    "    anchors = tf.cast(tf.reshape(ANCHORS, [1, 1, 1, ANCHORS.shape[0], 2]), dtype=tf.float32)  # [0,19] space\n",
    "    predictions_yx += coordinates\n",
    "    predictions_hw *= anchors\n",
    "    \n",
    "    # map from [0,19] space to [0,1] space\n",
    "    shape = tf.cast(tf.reshape([GRID_H, GRID_W], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    predictions_yx /= shape\n",
    "    predictions_hw /= shape\n",
    "    \n",
    "    return predictions_yx, predictions_hw\n",
    "\n",
    "def get_boxes_gt(args_map):\n",
    "    # extract ground truth bboxes wherever prob_obj = 1\n",
    "    mask_object = tf.cast(tf.reshape(args_map[1], [GRID_H, GRID_W, NUM_ANCHORS]), tf.bool)\n",
    "    bboxes = tf.boolean_mask(args_map[0], mask_object)\n",
    "    # bboxes.shape = [NUM_DETECTIONS, 4]; NUM_DETECTIONS vary with each image\n",
    "    \n",
    "    # pad bboxes so that bboxes is fixed dimension (fix NUM_DETECTIONS to MAX_DETECTIONS_PER_IMAGE)\n",
    "    pad = tf.zeros((MAX_DETECTIONS_PER_IMAGE - tf.shape(bboxes)[0], 4))  # TODO: when NUM_DETECTIONS > MAX_DETECTIONS_PER_IMAGE\n",
    "    bboxes = tf.concat([bboxes, pad], axis=0)\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def get_iou_scores(predictions_yx, predictions_hw, bboxes_gt):\n",
    "    # predictions_yx.shape = predictions_hw.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    # bboxes_gt.shape = [BATCH_SIZE, MAX_DETECTIONS_PER_IMAGE, 4]\n",
    "    \n",
    "    # compute ious for each anchor in each grid in axis=4\n",
    "    predictions_yx = tf.expand_dims(predictions_yx, 4)\n",
    "    predictions_hw = tf.expand_dims(predictions_hw, 4)\n",
    "    \n",
    "    predictions_min = predictions_yx - predictions_hw/2.\n",
    "    predictions_max = predictions_yx + predictions_hw/2.\n",
    "    \n",
    "    bboxes_gt = tf.reshape(bboxes_gt, [tf.shape(bboxes_gt)[0], 1, 1, 1, MAX_DETECTIONS_PER_IMAGE, 4])\n",
    "    bboxes_gt_yx = bboxes_gt[..., 0:2]\n",
    "    bboxes_gt_hw = bboxes_gt[..., 2:4]\n",
    "    \n",
    "    bboxes_gt_min = bboxes_gt_yx - bboxes_gt_hw/2.\n",
    "    bboxes_gt_max = bboxes_gt_yx + bboxes_gt_hw/2.\n",
    "    \n",
    "    intersection_min = tf.maximum(predictions_min, bboxes_gt_min)\n",
    "    intersection_max = tf.minimum(predictions_max, bboxes_gt_max)\n",
    "    intersection_hw = tf.maximum(intersection_max - intersection_min, 0.)\n",
    "    area_intersection = intersection_hw[..., 0] * intersection_hw[..., 1]\n",
    "    \n",
    "    area_predictions = predictions_hw[...,0] * predictions_hw[...,1]\n",
    "    area_bboxes_gt = bboxes_gt_hw[...,0] * bboxes_gt_hw[...,1]\n",
    "    area_union = area_bboxes_gt + area_predictions - area_intersection\n",
    "    iou = area_intersection / area_union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def get_confidence_loss(labels_prob_obj, iou_mask, predictions_prob_obj):\n",
    "    mask_object_absent = (1 - labels_prob_obj) * (1 - iou_mask)\n",
    "    loss_object_absent = mask_object_absent * tf.square(predictions_prob_obj)\n",
    "    \n",
    "    loss_object_present = labels_prob_obj * tf.square(1-predictions_prob_obj)\n",
    "    \n",
    "    loss_confidence = COEFF_LOSS_CONFIDENCE_OBJECT_ABSENT * loss_object_absent \\\n",
    "            + COEFF_LOSS_CONFIDENCE_OBJECT_PRESENT * loss_object_present\n",
    "    \n",
    "    return tf.reduce_sum(loss_confidence)\n",
    "    \n",
    "def get_classification_loss(labels_prob_obj, labels_class, predictions_prob_class):\n",
    "    labels_class = tf.cast(labels_class, tf.int32)\n",
    "    labels_class = tf.one_hot(labels_class, NUM_OBJECTS)\n",
    "    \n",
    "    loss_classification = labels_prob_obj * tf.squared_difference(labels_class, predictions_prob_class)\n",
    "    \n",
    "    return tf.reduce_sum(loss_classification)\n",
    "\n",
    "def get_regression_loss(labels_bbox, predictions_bbox, labels_prob_obj):\n",
    "    loss_regression = labels_prob_obj * tf.squared_difference(labels_bbox,predictions_bbox)\n",
    "    \n",
    "    return tf.reduce_sum(loss_regression)\n",
    "\n",
    "def get_loss(predictions, labels): \n",
    "    # predictions.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS] (they are in grid space)\n",
    "    # labels.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 6]\n",
    "    \n",
    "    # apply corresponding transformations on predictions\n",
    "    predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class = apply_transformations(predictions)\n",
    "    \n",
    "    # map predictions_bbox to [0,1] space\n",
    "    predictions_yx, predictions_hw = grid2normalized(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # map labels_bbox to [0,1] space\n",
    "    labels_yx, labels_hw = grid2normalized(labels[...,0:2], labels[...,2:4])\n",
    "    \n",
    "    # get ground truth bboxes using labels_bbox & prob_obj in labels\n",
    "    labels_bbox = tf.concat([labels_yx, labels_hw], axis=-1)\n",
    "    bboxes_gt = tf.map_fn(get_boxes_gt, (labels_bbox, labels[...,5]), dtype=tf.float32)\n",
    "    \n",
    "    # compute iou scores for each anchor in each grid for all bboxes_gt\n",
    "    iou_scores = get_iou_scores(predictions_yx, predictions_hw, bboxes_gt)\n",
    "     \n",
    "    # keep anchors whose iou_scores are above THRESHOLD_IOU_SCORES\n",
    "    iou_scores_best = tf.reduce_max(iou_scores, axis=4, keep_dims=True)\n",
    "    iou_mask = tf.cast(iou_scores_best > THRESHOLD_IOU_SCORES, tf.float32)\n",
    "    \n",
    "    \n",
    "    ## Loss\n",
    "    # object confidence loss (presence and absence)\n",
    "    loss_confidence = get_confidence_loss(labels[...,5:6], iou_mask, predictions_prob_obj)\n",
    "    \n",
    "    # classification loss\n",
    "    loss_classification = get_classification_loss(labels[...,5:6], labels[...,4], predictions_prob_class)\n",
    "    \n",
    "    # regression loss\n",
    "    predictions_bbox = tf.concat([predictions_yx, predictions_hw], axis=-1)\n",
    "    loss_regression = get_regression_loss(labels_bbox, predictions_bbox, labels[...,5:6])\n",
    "    \n",
    "    # total loss\n",
    "    loss = ( loss_confidence + loss_classification + loss_regression ) / tf.cast(tf.shape(labels)[0], tf.float32)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    # dictionary as per saved TFRecord\n",
    "    keys_to_features = {\n",
    "        'img': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'label': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "    }\n",
    "\n",
    "    # parse record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    # decode image\n",
    "    img = tf.decode_raw(parsed['img'], tf.uint8)\n",
    "    img = tf.cast(tf.reshape(img, [IMG_H, IMG_W, 3]), tf.float32)\n",
    "    img /= 255.  # normalize\n",
    "\n",
    "    # decode label\n",
    "    label = tf.decode_raw(parsed['label'], tf.float32)\n",
    "    label = tf.reshape(label, [GRID_H, GRID_W, NUM_ANCHORS, 6])\n",
    "\n",
    "    return {'img': img}, label\n",
    "\n",
    "def input_fn_train(data_file):    \n",
    "    # dataset processing\n",
    "    dataset = tf.data.TFRecordDataset(data_file)\n",
    "    \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    img, label = iterator.get_next()\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def input_fn_predict(data_file):    \n",
    "    # dataset processing\n",
    "    dataset = tf.data.TFRecordDataset(data_file)\n",
    "    \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    img, label = iterator.get_next()\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def get_feature_columns():\n",
    "    img = tf.feature_column.numeric_column('img', dtype=tf.float32)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # input layer\n",
    "    features = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    imgs = tf.reshape(features, [-1, IMG_H, IMG_W, 3])\n",
    "    # imgs.shape = (BATCH_SIZE, 608, 608, 3)\n",
    "    \n",
    "    # dense\n",
    "    x = tf.image.resize_images(imgs, [64, 64])\n",
    "    x = tf.layers.flatten(x)\n",
    "    x = tf.layers.dense(x, 256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "    x = tf.layers.dense(x, 256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "    x = tf.layers.dense(x, GRID_H*GRID_W*NUM_ANCHORS*(5+NUM_OBJECTS))\n",
    "    predictions = tf.reshape(x, [-1, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS])\n",
    "    \n",
    "#     # CNN\n",
    "#     with tf.name_scope('CNN'):\n",
    "#         x = tf.layers.conv2d(imgs, filters=8, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "#         x = tf.layers.max_pooling2d(x, pool_size=4, strides=4)\n",
    "        \n",
    "#         # x.shape = (BATCH_SIZE, 152, 152, 8)\n",
    "\n",
    "#         x = tf.layers.conv2d(x, filters=64, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "#         x = tf.layers.max_pooling2d(x, pool_size=4, strides=4)\n",
    "#         # x.shape = (BATCH_SIZE, 38, 38, 64)\n",
    "\n",
    "#         x = tf.layers.conv2d(x, filters=125, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "#         x = tf.layers.max_pooling2d(x, pool_size=2, strides=2)\n",
    "#         # x.shape = (BATCH_SIZE, 19, 19, 125)\n",
    "\n",
    "#         predictions = tf.reshape(x, (-1, GRID_H, GRID_W, params['num_anchors'], 5+params['num_objects']))\n",
    "#         # output.shape = (BATCH_SIZE, 19, 19, 5, 25)\n",
    "    \n",
    "    ## PREDICT\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        \n",
    "        outputs = {\n",
    "            'imgs': imgs,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=outputs)\n",
    "    \n",
    "    # compute loss\n",
    "    with tf.name_scope('Loss'):\n",
    "        loss = get_loss(predictions, labels)\n",
    "    tf.summary.scalar('loss_summary', loss)\n",
    "    \n",
    "    ## EVALUATE\n",
    "#     # compute evaluation metrics\n",
    "#     mse = tf.metrics.mean_squared_error(labels=labels, predictions=predictions, name='mse_op')\n",
    "#     metrics = {'mse': mse}\n",
    "#     tf.summary.scalar('mse', mse[1])\n",
    "#     if mode == tf.estimator.ModeKeys.EVAL:\n",
    "#         return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    ## TRAIN\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_session_config': None, '_task_id': 0, '_keep_checkpoint_max': 1, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_save_summary_steps': 10, '_model_dir': 'model', '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d4f01f2b0>, '_service': None, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# get feature columns\n",
    "feature_columns = get_feature_columns()\n",
    "\n",
    "# training configuration\n",
    "run_config = tf.estimator.RunConfig().replace(keep_checkpoint_max=1, save_summary_steps=10)\n",
    "\n",
    "# define model\n",
    "model = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    params={\n",
    "        'feature_columns': feature_columns,\n",
    "        'num_anchors': ANCHORS.shape[0],\n",
    "        'num_objects': NUM_OBJECTS\n",
    "    },\n",
    "    model_dir=MODEL_DIR,\n",
    "    config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into model/model.ckpt.\n",
      "INFO:tensorflow:step = 1001, loss = 0.0021196129\n",
      "INFO:tensorflow:global_step/sec: 64.6897\n",
      "INFO:tensorflow:step = 1101, loss = 0.0013777023 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0274\n",
      "INFO:tensorflow:step = 1201, loss = 0.021707235 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8155\n",
      "INFO:tensorflow:step = 1301, loss = 0.37911776 (1.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9915\n",
      "INFO:tensorflow:step = 1401, loss = 0.12756398 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0025\n",
      "INFO:tensorflow:step = 1501, loss = 0.0681815 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2343\n",
      "INFO:tensorflow:step = 1601, loss = 0.0029158897 (1.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5191\n",
      "INFO:tensorflow:step = 1701, loss = 0.0016395262 (1.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0544\n",
      "INFO:tensorflow:step = 1801, loss = 0.0014151437 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2406\n",
      "INFO:tensorflow:step = 1901, loss = 0.00051821384 (1.384 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00073411.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f5d4f01fbe0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=lambda: input_fn_train(DATA_TRAIN), steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(input_fn=lambda: input_fn_predict(DATA_TRAIN))\n",
    "\n",
    "idx = 0\n",
    "iteration = 0\n",
    "for p in predictions:\n",
    "    img, p = p['imgs'], p['predictions']\n",
    "    if iteration == idx:\n",
    "        break\n",
    "    iteration += 1\n",
    "\n",
    "img = draw_adjusted_anchors(img, p, 'pred')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(p[0,0,:,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def draw_adjusted_anchor(img, idx_h, idx_w, idx_a, label_bbox):\n",
    "    # box_adjustment.shape = [5,]\n",
    "    \n",
    "    center_y = (label_bbox[0]+idx_h)*GRID_SIZE\n",
    "    center_x = (label_bbox[1]+idx_w)*GRID_SIZE\n",
    "    \n",
    "    height = label_bbox[2] * ANCHORS[idx_a,0] * GRID_SIZE\n",
    "    width = label_bbox[3] * ANCHORS[idx_a,1] * GRID_SIZE\n",
    "     \n",
    "    left = int(center_x - width/2)\n",
    "    top = int(center_y - height/2)\n",
    "    right = int(left + width)\n",
    "    bottom = int(top + height)\n",
    "\n",
    "    img = cv2.rectangle(img, (left, top), (right, bottom), color=(255, 0, 0), thickness=3)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def draw_adjusted_anchors(img, label, data='gt'):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    for idx_h in range(GRID_H):\n",
    "        for idx_w in range(GRID_W):\n",
    "            for idx_a in range(NUM_ANCHORS):\n",
    "                if sigmoid(label[idx_h, idx_w, idx_a, 5]) > 0:\n",
    "                    bbox = label[idx_h, idx_w, idx_a, :4]\n",
    "                    if data == 'pred':\n",
    "                        bbox[0:2] = sigmoid(bbox[0:2])  # to keep offsets in interval [0,1]\n",
    "                        bbox[2:4] = np.exp(bbox[2:4])  # to keep width and height to be positive\n",
    "                    \n",
    "                    img = draw_adjusted_anchor(img, idx_h, idx_w, idx_a, bbox)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction2output(prediction):\n",
    "    # get boxes (bbox, class)\n",
    "    boxes = get_boxes(prediction)\n",
    "    \n",
    "    # perform nms\n",
    "    boxes_nms = perform_nms(boxes)\n",
    "    \n",
    "    # draw boxes on image\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center2corner(out_yx, out_hw):\n",
    "    # out_yx.shape = [GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    \n",
    "    box_min = out_yx - (out_hw/2.)\n",
    "    box_max = out_yx + (out_hw/2.)\n",
    "    \n",
    "    out_corners = tf.concat([box_min[...,0:1], box_min[...,1:2], box_max[...,0:1], box_max[...,1:2]], axis=-1)\n",
    "    return out_corners\n",
    "\n",
    "def get_filtered_output(map_params):\n",
    "    # this is done to use batch \n",
    "    out_corners, out_prob_obj, out_prob_class = map_params[0], map_params[1], map_params[2]\n",
    "    \n",
    "    # compute overall prob for each anchor in each grid\n",
    "    out_prob = out_prob_obj * out_prob_class\n",
    "    \n",
    "    # get max prob among all classes at each anchor in each grid\n",
    "    class_max = tf.argmax(out_prob, axis=-1)\n",
    "    prob_class = tf.reduce_max(out_prob, axis=-1)\n",
    "    \n",
    "    # compute filter mask\n",
    "    mask_filter = prob_class >= THRESHOLD_OUT_PROB\n",
    "    \n",
    "    # apply mask on output\n",
    "    box_filtered = tf.boolean_mask(out_corners, mask_filter)\n",
    "    prob_filtered = tf.boolean_mask(prob_class, mask_filter)\n",
    "    class_filtered = tf.boolean_mask(class_max, mask_filter)\n",
    "    return box_filtered, prob_filtered, class_filtered\n",
    "\n",
    "def get_predictions(output):\n",
    "    # output.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5+20]\n",
    "    \n",
    "    # split output\n",
    "    out_yx, out_hw, out_prob_obj, out_prob_class = get_mapped_output(output)\n",
    "    \n",
    "    # convert boxes from center coordinates to corner coordinates\n",
    "    out_corners = center2corner(out_yx, out_hw)\n",
    "    \n",
    "    # filter output (needs to be done separately for each image in batch)\n",
    "    box_filtered, prob_filtered, class_filtered = tf.map_fn(\n",
    "        get_filtered_output, \n",
    "        (out_corners, out_prob_obj, out_prob_class),\n",
    "        dtype=(tf.float32, tf.float32, tf.int64)\n",
    "    )\n",
    "    \n",
    "    # scale boxes from [0,1] to image space\n",
    "    img_space = tf.reshape(tf.cast(tf.stack([IMG_H, IMG_W, IMG_H, IMG_W]), tf.float32), [1, 1, 4])\n",
    "    box_filtered = box_filtered * img_space\n",
    "    \n",
    "    # perform non-max suppression\n",
    "    max_objects = tf.ones(tf.shape(box_filtered)[0], dtype=tf.int32) * MAX_OBJECTS\n",
    "    box_nms_indices = tf.map_fn(lambda x: tf.image.non_max_suppression(x[0], x[1], x[2], THRESHOLD_IOU_NMS), (box_filtered, prob_filtered, max_objects), dtype=tf.int32)\n",
    "    box_nms = tf.map_fn(lambda x: tf.gather(x[0], x[1]), (box_filtered, box_nms_indices), dtype=tf.float32)\n",
    "    prob_nms = tf.map_fn(lambda x: tf.gather(x[0], x[1]), (prob_filtered, box_nms_indices), dtype=tf.float32)\n",
    "    class_nms = tf.map_fn(lambda x: tf.gather(x[0], x[1]), (class_filtered, box_nms_indices), dtype=tf.int64)\n",
    "    \n",
    "    return box_nms, prob_nms, class_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_mapped_output(output):\n",
    "#     anchors = tf.cast(tf.reshape(ANCHORS, [1, 1, 1, ANCHORS.shape[0], 2]), dtype=tf.float32)  # try using variable for ANCHORS\n",
    "    \n",
    "#     # create cartesian grid on output space\n",
    "#     coordinates_y = tf.range(GRID_H)\n",
    "#     coordinates_x = tf.range(GRID_W)\n",
    "#     x, y = tf.meshgrid(coordinates_x, coordinates_y)\n",
    "#     x = tf.reshape(x, [-1])\n",
    "#     y = tf.reshape(y, [-1])\n",
    "#     coordinates = tf.stack([y, x], 1)\n",
    "#     coordinates = tf.reshape(coordinates, [1, GRID_H, GRID_W, 1, 2])\n",
    "#     coordinates = tf.cast(coordinates, tf.float32)\n",
    "    \n",
    "#     # change dimensions of tensors for broadcasting\n",
    "#     output = tf.reshape(output, [-1, GRID_H, GRID_W, ANCHORS.shape[0], 5+NUM_OBJECTS])\n",
    "#     shape = tf.cast(tf.reshape(tf.shape(output)[1:3], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    \n",
    "#     # map output to input space (also split yx, hw, prob_obj, prob_class)\n",
    "#     out_yx = tf.sigmoid(output[..., :2])  # sigmoid to keep centers in interval [0,1]\n",
    "#     out_hw = tf.exp(output[..., 2:4])  # exp to keep values positive\n",
    "#     out_yx = (out_yx + coordinates) / shape  # maps values to [0,1] input image space\n",
    "#     out_hw = out_hw * anchors / shape\n",
    "    \n",
    "#     # get corresponding probabilities\n",
    "#     out_prob_obj = tf.sigmoid(output[..., 4:5])\n",
    "#     out_prob_class = tf.nn.softmax(output[..., 5:])\n",
    "    \n",
    "#     return out_yx, out_hw, out_prob_obj, out_prob_class\n",
    "    \n",
    "\n",
    "# def get_iou(out_yx, out_hw, targets):\n",
    "#     # out_yx.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "#     # targets.shape = [BATCH_SIZE, MAX_OBJECTS, 5]\n",
    "    \n",
    "#     # compute ious for each anchor in each grid in axis=4\n",
    "#     out_yx = tf.expand_dims(out_yx, 4)\n",
    "#     out_hw = tf.expand_dims(out_hw, 4)\n",
    "#     out_min = out_yx - out_hw/2.\n",
    "#     out_max = out_yx + out_hw/2.\n",
    "    \n",
    "#     targets = tf.reshape(targets, [tf.shape(targets)[0], 1, 1, 1, MAX_OBJECTS, 5])\n",
    "#     targets_yx = targets[..., 0:2]\n",
    "#     targets_hw = targets[..., 2:4]\n",
    "    \n",
    "#     targets_min = targets_yx - targets_hw/2.\n",
    "#     targets_max = targets_yx + targets_hw/2.\n",
    "    \n",
    "#     intersection_min = tf.maximum(out_min, targets_min)\n",
    "#     intersection_max = tf.minimum(out_max, targets_max)\n",
    "#     intersection_hw = tf.maximum(intersection_max - intersection_min, 0.)\n",
    "#     area_intersection = intersection_hw[..., 0] * intersection_hw[..., 1]\n",
    "    \n",
    "#     area_out = out_hw[...,0] * out_hw[...,1]\n",
    "#     area_targets = targets[...,0] * targets[...,1]\n",
    "#     area_union = area_targets + area_out - area_intersection\n",
    "#     iou = area_intersection / area_union\n",
    "    \n",
    "#     return iou\n",
    "    \n",
    "\n",
    "# def get_confidence_loss(out_flag_object, flag_object, out_prob_obj):\n",
    "#     mask_object_absent = (1 - out_flag_object) * (1 - flag_object)\n",
    "#     loss_object_absent = mask_object_absent * tf.square(out_prob_obj)\n",
    "    \n",
    "#     loss_object_present = flag_object * tf.square(1-out_prob_obj)\n",
    "#     return loss_object_absent + SCALE_LOSS_CONFIDENCE_OBJECT_PRESENT*loss_object_present\n",
    "    \n",
    "# def get_classification_loss(flag_object, box_adjustments, out_prob_class):\n",
    "#     classes = tf.cast(box_adjustments[...,4], tf.int32)\n",
    "#     classes = tf.one_hot(classes, NUM_OBJECTS)\n",
    "    \n",
    "#     loss_classification = flag_object * tf.square(classes - out_prob_class)\n",
    "    \n",
    "#     return loss_classification\n",
    "\n",
    "# def get_regression_loss(out_box_adjustments, flag_object, box_adjustments):\n",
    "#     loss_regression = flag_object * tf.square(box_adjustments[...,:4] - out_box_adjustments)\n",
    "    \n",
    "#     return loss_regression\n",
    "\n",
    "\n",
    "    # split labels \n",
    "#     mask_object = tf.cast(tf.reshape(labels[...,5], [-1, GRID_H, GRID_W, NUM_ANCHORS]), tf.bool)\n",
    "#     labels_box = labels[...,0:5]\n",
    "    \n",
    "#     # apply mask to differentiate object vs no_object areas\n",
    "#     labels_masked = tf.boolean_mask(labels_box, mask_object)\n",
    "#     predictions_masked = tf.boolean_mask(predictions, mask_object)\n",
    "#     predictions_masked_negative = tf.boolean_mask(predictions, tf.logical_not(mask_object))\n",
    "    \n",
    "#     # apply corresponding transformations on predictions\n",
    "#     predictions_masked_yx = tf.sigmoid(predictions_masked[...,0:2])\n",
    "#     predictions_masked_hw = tf.exp(predictions_masked[...,2:4])\n",
    "#     predictions_masked_obj = tf.sigmoid(predictions_masked[...,4])\n",
    "#     predictions_masked_no_obj = tf.sigmoid(predictions_masked_negative[...,4])\n",
    "#     predictions_masked_class = tf.nn.softmax(predictions_masked[...,5:])\n",
    "    \n",
    "#     # split labels_box\n",
    "#     labels_masked_yx = labels_masked[...,0:2]\n",
    "#     labels_masked_hw = labels_masked[...,2:4]\n",
    "#     labels_masked_class = labels_masked[...,4]\n",
    "#     labels_masked_one_hot = tf.reshape(tf.one_hot(tf.cast(labels_masked_class, tf.int32), NUM_OBJECTS), [-1, NUM_OBJECTS])\n",
    "    \n",
    "#     # compute loss\n",
    "#     loss_object = tf.reduce_sum(tf.square(predictions_masked_obj - 1))\n",
    "#     loss_no_object = tf.reduce_sum(tf.square(predictions_masked_no_obj))\n",
    "#     loss_yx = tf.reduce_sum(tf.square(predictions_masked_yx - labels_masked_yx))\n",
    "#     loss_hw = tf.reduce_sum(tf.square(tf.sqrt(predictions_masked_hw) - tf.sqrt(labels_masked_hw)))\n",
    "#     loss_class = tf.reduce_sum(tf.square(predictions_masked_class - labels_masked_one_hot))\n",
    "    \n",
    "#     loss = tf.cast(1/tf.shape(predictions)[0], tf.float32) * (COOEFFICIENT_OBJ*loss_object + COOEFFICIENT_NO_OBJ*loss_no_object + COOEFFICIENT_REG*(loss_yx + loss_hw) + loss_class)\n",
    "############################\n",
    "#     # map output from grid space to [0,1] space\n",
    "#     out_yx, out_hw, out_prob_obj, out_prob_class = get_mapped_output(output)\n",
    "    \n",
    "#     # get iou for all boxes wrt each anchor in each grid\n",
    "#     iou = get_iou(out_yx, out_hw, targets)\n",
    "    \n",
    "#     # keep best bbox for each anchor for each grid as per iou\n",
    "#     iou_best = tf.reduce_max(iou, axis=4, keepdims=True)\n",
    "    \n",
    "#     # threshold over ious\n",
    "#     out_flag_object = tf.cast(iou_best > THRESHOLD_IOU, tf.float32)\n",
    "    \n",
    "#     # object presence loss (confidence)\n",
    "#     loss_confidence = get_confidence_loss(out_flag_object, flag_object, out_prob_obj)\n",
    "    \n",
    "#     # classification loss\n",
    "#     loss_classification = get_classification_loss(flag_object, box_adjustments, out_prob_class)\n",
    "    \n",
    "#     # regression loss\n",
    "#     out_box_adjustments = tf.concat([tf.sigmoid(output[...,0:2]), tf.exp(output[...,2:4])], axis=-1)\n",
    "#     loss_regression = get_regression_loss(out_box_adjustments, flag_object, box_adjustments)\n",
    "    \n",
    "#     # accumulate loss\n",
    "#     loss_confidence_sum = tf.reduce_sum(loss_confidence)\n",
    "#     loss_classification_sum = tf.reduce_sum(loss_classification)\n",
    "#     loss_regression_sum = tf.reduce_sum(loss_regression)\n",
    "    \n",
    "#     loss = tf.cast(1/tf.shape(targets)[0], tf.float32) * 0.5 * (loss_confidence_sum + loss_classification_sum + loss_regression_sum)\n",
    "    \n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# output = tf.random_normal([BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5+20])\n",
    "# b, p, c = get_predictions(output)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     b, p, c = sess.run([b, p, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# f, l = input_fn_train(DATA_TRAIN)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     f, l = sess.run([f,l])\n",
    "\n",
    "# idx_in_batch = 0\n",
    "# l = l['targets'][idx_in_batch]\n",
    "\n",
    "# plt.imshow(f['img'][0,:,:,:])\n",
    "# for idx_object in range(l.shape[0]):\n",
    "#     plt.scatter((l[idx_object,1]-l[idx_object,3]/2)*IMG_W, (l[idx_object,0]-l[idx_object,2]/2)*IMG_H, color='w')\n",
    "#     plt.scatter((l[idx_object,1]-l[idx_object,3]/2)*IMG_W, (l[idx_object,0]+l[idx_object,2]/2)*IMG_H, color='w')\n",
    "#     plt.scatter((l[idx_object,1]+l[idx_object,3]/2)*IMG_W, (l[idx_object,0]-l[idx_object,2]/2)*IMG_H, color='w')\n",
    "#     plt.scatter((l[idx_object,1]+l[idx_object,3]/2)*IMG_W, (l[idx_object,0]+l[idx_object,2]/2)*IMG_H, color='w')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
