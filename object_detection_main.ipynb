{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TFRECORDS = 'data_small_tfrecords'\n",
    "DATA_TRAIN = glob('./'+DIR_TFRECORDS+'/*.tfrecords')\n",
    "\n",
    "ANCHORS = np.array(\n",
    "    [\n",
    "        [1.73145, 1.3221],\n",
    "        [4.00944, 3.19275],\n",
    "        [8.09892, 5.05587],\n",
    "        [4.84053, 9.47112],\n",
    "        [10.0071, 11.2364]\n",
    "    ]\n",
    ")\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "MAX_OBJECTS = 10  # check later (ensure it matches with writing file)\n",
    "NUM_OBJECTS = 20\n",
    "\n",
    "GRID_SIZE = 32\n",
    "GRID_H, GRID_W = 19, 19\n",
    "IMG_H, IMG_W = 608, 608  # GRID_H * GRID_SIZE = 19 * 32 = 608\n",
    "THRESHOLD_IOU = 0.6\n",
    "SCALE_LOSS_CONFIDENCE_OBJECT_PRESENT = 5\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "MODEL_DIR = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapped_output(output):\n",
    "    anchors = tf.cast(tf.reshape(ANCHORS, [1, 1, 1, ANCHORS.shape[0], 2]), dtype=tf.float32)  # try using variable for ANCHORS\n",
    "    \n",
    "    # create cartesian grid on output space\n",
    "    coordinates_y = tf.range(GRID_H)\n",
    "    coordinates_x = tf.range(GRID_W)\n",
    "    x, y = tf.meshgrid(coordinates_x, coordinates_y)\n",
    "    x = tf.reshape(x, [-1])\n",
    "    y = tf.reshape(y, [-1])\n",
    "    coordinates = tf.stack([y, x], 1)\n",
    "    coordinates = tf.reshape(coordinates, [1, GRID_H, GRID_W, 1, 2])\n",
    "    coordinates = tf.cast(coordinates, tf.float32)\n",
    "    \n",
    "    # change dimensions of tensors for broadcasting\n",
    "    output = tf.reshape(output, [-1, GRID_H, GRID_W, ANCHORS.shape[0], 5+NUM_OBJECTS])\n",
    "    shape = tf.cast(tf.reshape(tf.shape(output)[1:3], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    \n",
    "    # map output to input space (also split yx, hw, prob_obj, prob_class)\n",
    "    out_yx = tf.sigmoid(output[..., :2])  # sigmoid to keep centers in interval [0,1]\n",
    "    out_hw = tf.exp(output[..., 2:4])  # exp to keep values positive\n",
    "    out_yx = (out_yx + coordinates) / shape  # maps values to [0,1] input image space\n",
    "    out_hw = out_hw * anchors / shape\n",
    "    \n",
    "    # get corresponding probabilities\n",
    "    out_prob_obj = tf.sigmoid(output[..., 4:5])\n",
    "    out_prob_class = tf.nn.softmax(output[..., 5:])\n",
    "    \n",
    "    return out_yx, out_hw, out_prob_obj, out_prob_class\n",
    "    \n",
    "\n",
    "def get_iou(out_yx, out_hw, targets):\n",
    "    # out_yx.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    # targets.shape = [BATCH_SIZE, MAX_OBJECTS, 5]\n",
    "    \n",
    "    # compute ious for each anchor in each grid in axis=4\n",
    "    out_yx = tf.expand_dims(out_yx, 4)\n",
    "    out_hw = tf.expand_dims(out_hw, 4)\n",
    "    out_min = out_yx - out_hw/2.\n",
    "    out_max = out_yx + out_hw/2.\n",
    "    \n",
    "    targets = tf.reshape(targets, [tf.shape(targets)[0], 1, 1, 1, MAX_OBJECTS, 5])\n",
    "    targets_yx = targets[..., 0:2]\n",
    "    targets_hw = targets[..., 2:4]\n",
    "    \n",
    "    targets_min = targets_yx - targets_hw/2.\n",
    "    targets_max = targets_yx + targets_hw/2.\n",
    "    \n",
    "    intersection_min = tf.maximum(out_min, targets_min)\n",
    "    intersection_max = tf.minimum(out_max, targets_max)\n",
    "    intersection_hw = tf.maximum(intersection_max - intersection_min, 0.)\n",
    "    area_intersection = intersection_hw[..., 0] * intersection_hw[..., 1]\n",
    "    \n",
    "    area_out = out_hw[...,0] * out_hw[...,1]\n",
    "    area_targets = targets[...,0] * targets[...,1]\n",
    "    area_union = area_targets + area_out - area_intersection\n",
    "    iou = area_intersection / area_union\n",
    "    \n",
    "    return iou\n",
    "    \n",
    "\n",
    "def get_confidence_loss(out_flag_object, flag_object, out_prob_obj):\n",
    "    mask_object_absent = (1 - out_flag_object) * (1 - flag_object)\n",
    "    loss_object_absent = mask_object_absent * tf.square(out_prob_obj)\n",
    "    \n",
    "    loss_object_present = flag_object * tf.square(1-out_prob_obj)\n",
    "    return loss_object_absent + SCALE_LOSS_CONFIDENCE_OBJECT_PRESENT*loss_object_present\n",
    "    \n",
    "def get_classification_loss(flag_object, box_adjustments, out_prob_class):\n",
    "    classes = tf.cast(box_adjustments[...,4], tf.int32)\n",
    "    classes = tf.one_hot(classes, NUM_OBJECTS)\n",
    "    \n",
    "    loss_classification = flag_object * tf.square(classes - out_prob_class)\n",
    "    \n",
    "    return loss_classification\n",
    "\n",
    "def get_regression_loss(out_box_adjustments, flag_object, box_adjustments):\n",
    "    loss_regression = flag_object * tf.square(box_adjustments[...,:4] - out_box_adjustments)\n",
    "    \n",
    "    return loss_regression\n",
    "    \n",
    "def get_loss(output, targets, flag_object, box_adjustments):\n",
    "    # output.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS]\n",
    "    # targets.shape = [BATCH_SIZE, MAX_OBJECTS, 5]\n",
    "    # flag_object.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 1]\n",
    "    # box_adjustments.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5]\n",
    "\n",
    "    # map output (from CNN) to input image space i.e. [0,1]\n",
    "    out_yx, out_hw, out_prob_obj, out_prob_class = get_mapped_output(output)\n",
    "    \n",
    "#     # get iou for all boxes wrt each anchor box in each grid\n",
    "    iou = get_iou(out_yx, out_hw, targets)\n",
    "    \n",
    "#     # keep best bbox for each anchor for each grid as per iou\n",
    "    iou_best = tf.reduce_max(iou, axis=4, keepdims=True)\n",
    "    \n",
    "#     # threshold over ious\n",
    "    out_flag_object = tf.cast(iou_best > THRESHOLD_IOU, tf.float32)\n",
    "    \n",
    "#     # object presence loss (confidence)\n",
    "    loss_confidence = get_confidence_loss(out_flag_object, flag_object, out_prob_obj)\n",
    "    \n",
    "#     # classification loss\n",
    "    loss_classification = get_classification_loss(flag_object, box_adjustments, out_prob_class)\n",
    "    \n",
    "#     # regression loss\n",
    "    out_box_adjustments = tf.concat([tf.sigmoid(output[...,0:2]), output[...,2:4]], axis=-1)\n",
    "    loss_regression = get_regression_loss(out_box_adjustments, flag_object, box_adjustments)\n",
    "    \n",
    "#     # accumulate loss\n",
    "    loss_confidence_sum = tf.reduce_sum(loss_confidence)\n",
    "    loss_classification_sum = tf.reduce_sum(loss_classification)\n",
    "    loss_regression_sum = tf.reduce_sum(loss_regression)\n",
    "    \n",
    "    loss = tf.cast(1/tf.shape(targets)[0], tf.float32) * 0.5 * (loss_confidence_sum + loss_classification_sum + loss_regression_sum)\n",
    "    \n",
    "#     y = tf.layers.flatten(output)\n",
    "#     y = tf.layers.dense(y, units=1)\n",
    "    \n",
    "#     loss = tf.reduce_sum(y-tf.constant(1.))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    # dictionary as per saved TFRecord\n",
    "    keys_to_features = {\n",
    "        'img': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        #'num_objects': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'targets': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'flag_object': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'box_adjustments': tf.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    }\n",
    "\n",
    "    # parse record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    # decode image\n",
    "    img = tf.decode_raw(parsed['img'], tf.float32)\n",
    "    img = tf.reshape(img, [IMG_H, IMG_W, 3])\n",
    "\n",
    "    # decode label\n",
    "    targets = tf.decode_raw(parsed['targets'], tf.float32)\n",
    "    targets = tf.reshape(targets, [MAX_OBJECTS, 5])\n",
    "\n",
    "    # decode other matrices\n",
    "    flag_object = tf.decode_raw(parsed['flag_object'], tf.float32)\n",
    "    flag_object = tf.reshape(flag_object, [GRID_H, GRID_W, ANCHORS.shape[0], 1])\n",
    "    box_adjustments = tf.decode_raw(parsed['box_adjustments'], tf.float32)\n",
    "    box_adjustments = tf.reshape(box_adjustments, [GRID_H, GRID_W, ANCHORS.shape[0], 5])\n",
    "\n",
    "    return {'img': img}, targets, flag_object, box_adjustments\n",
    "\n",
    "def input_fn_train(data_file):    \n",
    "    # dataset processing\n",
    "    dataset = tf.data.TFRecordDataset(data_file)\n",
    "    \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, targets, flag_object, box_adjustments = iterator.get_next()\n",
    "    \n",
    "    return features, {'targets': targets, 'flag_object': flag_object, 'box_adjustments': box_adjustments}\n",
    "\n",
    "def input_fn_predict(data_file):    \n",
    "    # dataset processing\n",
    "    dataset = tf.data.TFRecordDataset(data_file)\n",
    "    \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, targets, flag_object, box_adjustments = iterator.get_next()\n",
    "    \n",
    "    return features, {'targets': targets, 'flag_object': flag_object, 'box_adjustments': box_adjustments}\n",
    "\n",
    "def get_feature_columns():\n",
    "    img = tf.feature_column.numeric_column('img', dtype=tf.float32)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # input layer\n",
    "    features = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    imgs = tf.reshape(features, [-1, IMG_H, IMG_W, 3])\n",
    "    # imgs.shape = (BATCH_SIZE, 608, 608, 3)\n",
    "    \n",
    "    # CNN\n",
    "    x = tf.layers.conv2d(imgs, filters=8, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=4, strides=4)\n",
    "    # x.shape = (BATCH_SIZE, 152, 152, 8)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=64, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=4, strides=4)\n",
    "    # x.shape = (BATCH_SIZE, 38, 38, 64)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=125, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2)\n",
    "    # x.shape = (BATCH_SIZE, 19, 19, 125)\n",
    "    \n",
    "    output = tf.reshape(x, (-1, GRID_H, GRID_W, params['num_anchors'], 5+params['num_objects']))\n",
    "    # predictions.shape = (BATCH_SIZE, 19, 19, 5, 25)\n",
    "    \n",
    "    ## PREDICT\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        outputs = {\n",
    "            'output': output,\n",
    "            'imgs': imgs\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=outputs)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = get_loss(output, labels['targets'], labels['flag_object'], labels['box_adjustments'])\n",
    "    tf.summary.scalar('loss_summary', loss)\n",
    "    \n",
    "    ## EVALUATE\n",
    "#     # compute evaluation metrics\n",
    "#     mse = tf.metrics.mean_squared_error(labels=labels, predictions=predictions, name='mse_op')\n",
    "#     metrics = {'mse': mse}\n",
    "#     tf.summary.scalar('mse', mse[1])\n",
    "#     if mode == tf.estimator.ModeKeys.EVAL:\n",
    "#         return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    ## TRAIN\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f410e5255c0>, '_task_id': 0, '_task_type': 'worker', '_num_worker_replicas': 1, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_save_checkpoints_secs': 600, '_evaluation_master': '', '_save_checkpoints_steps': None, '_service': None, '_is_chief': True, '_save_summary_steps': 10, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_keep_checkpoint_max': 1, '_log_step_count_steps': 100, '_model_dir': 'model', '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# get feature columns\n",
    "feature_columns = get_feature_columns()\n",
    "\n",
    "# training configuration\n",
    "run_config = tf.estimator.RunConfig().replace(keep_checkpoint_max=1, save_summary_steps=10)\n",
    "\n",
    "# define model\n",
    "model = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    params={\n",
    "        'feature_columns': feature_columns,\n",
    "        'num_anchors': ANCHORS.shape[0],\n",
    "        'num_objects': NUM_OBJECTS\n",
    "    },\n",
    "    model_dir=MODEL_DIR,\n",
    "    config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 101 into model/model.ckpt.\n",
      "INFO:tensorflow:loss = 214.83192, step = 101\n",
      "INFO:tensorflow:Saving checkpoints for 200 into model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 214.95824.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f410e525f28>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=lambda: input_fn_train(DATA_TRAIN), steps=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn=lambda: input_fn_predict(DATA_TRAIN))\n",
    "\n",
    "for p in predictions:\n",
    "    i = p['imgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# f, l = input_fn_train(DATA_TRAIN)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     f, l = sess.run([f,l])\n",
    "\n",
    "# idx_in_batch = 0\n",
    "# l = l['targets'][idx_in_batch]\n",
    "\n",
    "# plt.imshow(f['img'][0,:,:,:])\n",
    "# for idx_object in range(l.shape[0]):\n",
    "#     plt.scatter((l[idx_object,1]-l[idx_object,3]/2)*IMG_W, (l[idx_object,0]-l[idx_object,2]/2)*IMG_H, color='w')\n",
    "#     plt.scatter((l[idx_object,1]-l[idx_object,3]/2)*IMG_W, (l[idx_object,0]+l[idx_object,2]/2)*IMG_H, color='w')\n",
    "#     plt.scatter((l[idx_object,1]+l[idx_object,3]/2)*IMG_W, (l[idx_object,0]-l[idx_object,2]/2)*IMG_H, color='w')\n",
    "#     plt.scatter((l[idx_object,1]+l[idx_object,3]/2)*IMG_W, (l[idx_object,0]+l[idx_object,2]/2)*IMG_H, color='w')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((1,19,19,1,2))\n",
    "y = np.ones((8,19,19,5,2))\n",
    "\n",
    "print( (x+y).shape )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
