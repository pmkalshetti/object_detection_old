{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TFRECORDS = 'dummy_data'\n",
    "DATA_TRAIN = glob('./'+DIR_TFRECORDS+'/*.tfrecords')\n",
    "\n",
    "NUM_OBJECTS = 20\n",
    "MAX_DETECTIONS_PER_IMAGE = 20\n",
    "\n",
    "GRID_SIZE = 304#32\n",
    "GRID_H, GRID_W = 2,2#19, 19\n",
    "\n",
    "ANCHORS_NORMALIZED = np.array(\n",
    "    [\n",
    "        [0.09112895, 0.06958421],\n",
    "        [0.21102316, 0.16803947],\n",
    "        [0.42625895, 0.26609842],\n",
    "        [0.25476474, 0.49848   ],\n",
    "        [0.52668947, 0.59138947]\n",
    "    ]\n",
    ")\n",
    "ANCHORS = ANCHORS_NORMALIZED * np.array([GRID_H, GRID_W])\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "\n",
    "IMG_H, IMG_W = 608, 608  # GRID_H * GRID_SIZE = 19 * 32 = 608\n",
    "\n",
    "COOEFFICIENT_OBJ = 1\n",
    "COOEFFICIENT_NO_OBJ = 1\n",
    "COOEFFICIENT_REG = 5\n",
    "\n",
    "THRESHOLD_IOU_SCORES = 0.5\n",
    "COEFF_LOSS_CONFIDENCE_OBJECT_PRESENT = 5\n",
    "COEFF_LOSS_CONFIDENCE_OBJECT_ABSENT = 1\n",
    "THRESHOLD_OUT_PROB = 0.5\n",
    "THRESHOLD_IOU_NMS = 0.5\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "MODEL_DIR = 'model'\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "def draw_adjusted_anchor(img, idx_h, idx_w, idx_a, label_bbox):\n",
    "    # box_adjustment.shape = [5,]\n",
    "    \n",
    "    center_y = (label_bbox[0]+idx_h)*GRID_SIZE\n",
    "    center_x = (label_bbox[1]+idx_w)*GRID_SIZE\n",
    "    \n",
    "    height = label_bbox[2] * ANCHORS[idx_a,0] * GRID_SIZE\n",
    "    width = label_bbox[3] * ANCHORS[idx_a,1] * GRID_SIZE\n",
    "     \n",
    "    left = int(center_x - width/2)\n",
    "    top = int(center_y - height/2)\n",
    "    right = int(left + width)\n",
    "    bottom = int(top + height)\n",
    "\n",
    "    img = cv2.rectangle(img, (left, top), (right, bottom), color=(0, 255, 0), thickness=3)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def label(img, label):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    for idx_h in range(GRID_H):\n",
    "        for idx_w in range(GRID_W):\n",
    "            for idx_a in range(NUM_ANCHORS):\n",
    "                if sigmoid(label[idx_h, idx_w, idx_a, 5]) > 0.1:\n",
    "                    bbox = label[idx_h, idx_w, idx_a, :4]\n",
    "                    img = draw_adjusted_anchor(img, idx_h, idx_w, idx_a, bbox)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def draw_output(img, output):\n",
    "    # unnormalize image\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    output = output.astype(np.int32)\n",
    "    for idx_box in range(output.shape[0]):\n",
    "        bbox = output[idx_box]\n",
    "        img = cv2.rectangle(img, (bbox[1], bbox[0]), (bbox[3], bbox[2]), color=(255, 0, 0), thickness=3)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv( x, \n",
    "          num_filters, \n",
    "          kernel_size, \n",
    "          strides = (1,1), \n",
    "          padding = 'same', \n",
    "          is_training = False, \n",
    "          activation = tf.nn.leaky_relu,\n",
    "          name = None) :\n",
    "    \n",
    "    assert name != None, 'ERROR: conv: parameter \\'name\\' must be provided!\\n'\n",
    "    \n",
    "    with tf.name_scope( name ) :\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        net = tf.layers.conv2d( inputs = x, \n",
    "                                filters = num_filters, \n",
    "                                kernel_size = kernel_size, \n",
    "                                strides = strides, \n",
    "                                padding = padding,\n",
    "                                kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d(), \n",
    "                                bias_initializer = tf.zeros_initializer() )\n",
    "        \n",
    "        # Batch Normalization\n",
    "        net = tf.layers.batch_normalization( inputs = net, \n",
    "                                             training = is_training )\n",
    "        \n",
    "        # Activation\n",
    "        net = activation( net, alpha=0.01 )\n",
    "        \n",
    "        return net\n",
    "\n",
    "def maxpool( x, pool_size, strides, padding='same', name=None ) :\n",
    "    \n",
    "    assert name != None, 'ERROR: maxpool: parameter \\'name\\' must be provided!\\n'\n",
    "    \n",
    "    with tf.name_scope( name ) :\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        net = tf.layers.max_pooling2d( inputs = x, \n",
    "                                       pool_size = pool_size, \n",
    "                                       strides = strides, \n",
    "                                       padding = padding, \n",
    "                                       name = name )\n",
    "        \n",
    "        return net\n",
    "\n",
    "def layer_concat( layer1_out, layer2_out, block_size ) :\n",
    "    layer2_out = tf.space_to_depth( layer2_out, block_size=block_size )\n",
    "    return tf.concat( [layer1_out, layer2_out], axis=3 )\n",
    "\n",
    "def YOLO_net( x, is_training ) : \n",
    "    \n",
    "    net = conv( x, 32, (3,3), is_training=is_training, name='conv1' )\n",
    "    net = maxpool( net, (2,2), (2,2), name='maxpool1' )\n",
    "    net = conv( net, 64, (3,3), is_training=is_training, name='conv2' )\n",
    "    net = maxpool( net, (2,2), (2,2), name='maxpool2' )\n",
    "    \n",
    "    net = conv( net, 128, (3,3), is_training=is_training, name='conv3' )\n",
    "    net = conv( net, 64, (1,1), is_training=is_training, name='conv4' )\n",
    "    net = conv( net, 128, (3,3), is_training=is_training, name='conv5' )\n",
    "    net = maxpool( net, (2,2), (2,2), name='maxpool5' )\n",
    "    \n",
    "    net = conv( net, 256, (3,3), is_training=is_training, name='conv6' )\n",
    "    net = conv( net, 128, (1,1), is_training=is_training, name='conv7' )\n",
    "    net = conv( net, 256, (3,3), is_training=is_training, name='conv8' )\n",
    "    net = maxpool( net, (2,2), (2,2), name='maxpool8' )\n",
    "    \n",
    "    net = conv( net, 512, (3,3), is_training=is_training, name='conv9' )\n",
    "    net = conv( net, 256, (1,1), is_training=is_training, name='conv10' )\n",
    "    net = conv( net, 512, (3,3), is_training=is_training, name='conv11' )\n",
    "    net = conv( net, 256, (1,1), is_training=is_training, name='conv12' )\n",
    "    skip_tail = conv( net, 512, (3,3), is_training=is_training, name='conv13' )\n",
    "    net = maxpool( skip_tail, (2,2), (2,2), name='maxpool13' )\n",
    "    \n",
    "    net = conv( net, 1024, (3,3), is_training=is_training, name='conv14' )\n",
    "    net = conv( net, 512, (1,1), is_training=is_training, name='conv15' )\n",
    "    net = conv( net, 1024, (3,3), is_training=is_training, name='conv16' )\n",
    "    net = conv( net, 512, (1,1), is_training=is_training, name='conv17' )\n",
    "    net = conv( net, 1024, (3,3), is_training=is_training, name='conv18' )\n",
    "    \n",
    "    net = conv( net, 1024, (3,3), is_training=is_training, name='conv19' )\n",
    "    net = conv( net, 1024, (3,3), is_training=is_training, name='conv20' )\n",
    "    skip_head = conv( skip_tail, 64, (3,3), is_training=is_training, name='conv21' )\n",
    "    net = layer_concat( net, skip_head, block_size=2 )\n",
    "    net = conv( net, 1024, (3,3), is_training=is_training, name='conv22' )\n",
    "    net = conv( net, NUM_ANCHORS * (NUM_OBJECTS + 5), (1,1), is_training=is_training, name='conv23' )\n",
    "    \n",
    "    out = tf.reshape( net, shape=(-1, GRID_H, GRID_W, NUM_ANCHORS, NUM_OBJECTS+5) )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(predictions):\n",
    "    predictions_yx = tf.sigmoid(predictions[..., 0:2])\n",
    "    predictions_hw = tf.exp(predictions[...,2:4])\n",
    "    predictions_prob_obj = tf.sigmoid(predictions[...,4:5])\n",
    "    predictions_prob_class = tf.nn.softmax(predictions[...,5:])\n",
    "    \n",
    "    return predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class\n",
    "\n",
    "def get_coordinates(h, w):\n",
    "    coordinates_y = tf.range(h)\n",
    "    coordinates_x = tf.range(w)\n",
    "    x, y = tf.meshgrid(coordinates_x, coordinates_y)\n",
    "    coordinates = tf.stack([y,x], axis=-1)\n",
    "    coordinates = tf.reshape(coordinates, [1, h, w, 1, 2])\n",
    "    coordinates = tf.cast(coordinates, tf.float32)\n",
    "    \n",
    "    return coordinates\n",
    "\n",
    "def grid2normalized(predictions_yx, predictions_hw):    \n",
    "    # create cartesian coordinates on grid space\n",
    "    coordinates = get_coordinates(GRID_H, GRID_W)\n",
    "    \n",
    "    # map from grid space to [0,19] space\n",
    "    anchors = tf.cast(tf.reshape(ANCHORS, [1, 1, 1, ANCHORS.shape[0], 2]), dtype=tf.float32)  # [0,19] space\n",
    "    predictions_yx += coordinates\n",
    "    predictions_hw *= anchors\n",
    "    \n",
    "    # map from [0,19] space to [0,1] space\n",
    "    shape = tf.cast(tf.reshape([GRID_H, GRID_W], [1, 1, 1, 1, 2]), tf.float32)\n",
    "    predictions_yx /= shape\n",
    "    predictions_hw /= shape\n",
    "    \n",
    "    return predictions_yx, predictions_hw\n",
    "\n",
    "def get_boxes_gt(args_map):\n",
    "    # extract ground truth bboxes wherever prob_obj = 1\n",
    "    mask_object = tf.cast(tf.reshape(args_map[1], [GRID_H, GRID_W, NUM_ANCHORS]), tf.bool)\n",
    "    bboxes = tf.boolean_mask(args_map[0], mask_object)\n",
    "    # bboxes.shape = [NUM_DETECTIONS, 4]; NUM_DETECTIONS vary with each image\n",
    "    \n",
    "    # pad bboxes so that bboxes is fixed dimension (fix NUM_DETECTIONS to MAX_DETECTIONS_PER_IMAGE)\n",
    "    pad = tf.zeros((MAX_DETECTIONS_PER_IMAGE - tf.shape(bboxes)[0], 4))  # TODO: when NUM_DETECTIONS > MAX_DETECTIONS_PER_IMAGE\n",
    "    bboxes = tf.concat([bboxes, pad], axis=0)\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def get_iou_scores(predictions_yx, predictions_hw, bboxes_gt):\n",
    "    # predictions_yx.shape = predictions_hw.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    # bboxes_gt.shape = [BATCH_SIZE, MAX_DETECTIONS_PER_IMAGE, 4]\n",
    "    \n",
    "    # compute ious for each anchor in each grid in axis=4\n",
    "    predictions_yx = tf.expand_dims(predictions_yx, 4)\n",
    "    predictions_hw = tf.expand_dims(predictions_hw, 4)\n",
    "    \n",
    "    predictions_min = predictions_yx - predictions_hw/2.\n",
    "    predictions_max = predictions_yx + predictions_hw/2.\n",
    "    \n",
    "    bboxes_gt = tf.reshape(bboxes_gt, [tf.shape(bboxes_gt)[0], 1, 1, 1, MAX_DETECTIONS_PER_IMAGE, 4])\n",
    "    bboxes_gt_yx = bboxes_gt[..., 0:2]\n",
    "    bboxes_gt_hw = bboxes_gt[..., 2:4]\n",
    "    \n",
    "    bboxes_gt_min = bboxes_gt_yx - bboxes_gt_hw/2.\n",
    "    bboxes_gt_max = bboxes_gt_yx + bboxes_gt_hw/2.\n",
    "    \n",
    "    intersection_min = tf.maximum(predictions_min, bboxes_gt_min)\n",
    "    intersection_max = tf.minimum(predictions_max, bboxes_gt_max)\n",
    "    intersection_hw = tf.maximum(intersection_max - intersection_min, 0.)\n",
    "    area_intersection = intersection_hw[..., 0] * intersection_hw[..., 1]\n",
    "    \n",
    "    area_predictions = predictions_hw[...,0] * predictions_hw[...,1]\n",
    "    area_bboxes_gt = bboxes_gt_hw[...,0] * bboxes_gt_hw[...,1]\n",
    "    area_union = area_bboxes_gt + area_predictions - area_intersection\n",
    "    iou = area_intersection / area_union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def get_confidence_loss(labels_prob_obj, iou_mask, predictions_prob_obj):\n",
    "    mask_object_absent = (1 - labels_prob_obj) * (1 - iou_mask)\n",
    "    loss_object_absent = mask_object_absent * tf.square(predictions_prob_obj)\n",
    "    \n",
    "    loss_object_present = labels_prob_obj * tf.square(1-predictions_prob_obj)\n",
    "    \n",
    "    loss_confidence = COEFF_LOSS_CONFIDENCE_OBJECT_ABSENT * loss_object_absent \\\n",
    "            + COEFF_LOSS_CONFIDENCE_OBJECT_PRESENT * loss_object_present\n",
    "    \n",
    "    return tf.reduce_sum(loss_confidence)\n",
    "    \n",
    "def get_classification_loss(labels_prob_obj, labels_class, predictions_prob_class):\n",
    "    labels_class = tf.cast(labels_class, tf.int32)\n",
    "    labels_class = tf.one_hot(labels_class, NUM_OBJECTS)\n",
    "    \n",
    "    loss_classification = labels_prob_obj * tf.squared_difference(labels_class, predictions_prob_class)\n",
    "    \n",
    "    return tf.reduce_sum(loss_classification)\n",
    "\n",
    "def get_regression_loss(labels_bbox, predictions_bbox, labels_prob_obj):\n",
    "    loss_regression = labels_prob_obj * tf.squared_difference(labels_bbox,predictions_bbox)\n",
    "    \n",
    "    return tf.reduce_sum(loss_regression)\n",
    "\n",
    "def get_loss(predictions, labels): \n",
    "    # predictions.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS] (they are in grid space)\n",
    "    # labels.shape = [BATCH_SIZE, GRID_H, GRID_W, NUM_ANCHORS, 6]\n",
    "    \n",
    "    # apply corresponding transformations on predictions\n",
    "    predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class = apply_transformations(predictions)\n",
    "    \n",
    "    # map predictions_bbox to [0,1] space\n",
    "    predictions_yx, predictions_hw = grid2normalized(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # map labels_bbox to [0,1] space\n",
    "    labels_yx, labels_hw = grid2normalized(labels[...,0:2], labels[...,2:4])\n",
    "    \n",
    "    # get ground truth bboxes using labels_bbox & prob_obj in labels\n",
    "    labels_bbox = tf.concat([labels_yx, labels_hw], axis=-1)\n",
    "    bboxes_gt = tf.map_fn(get_boxes_gt, (labels_bbox, labels[...,5]), dtype=tf.float32)\n",
    "    \n",
    "    # compute iou scores for each anchor in each grid for all bboxes_gt\n",
    "    iou_scores = get_iou_scores(predictions_yx, predictions_hw, bboxes_gt)\n",
    "     \n",
    "    # keep anchors whose iou_scores are above THRESHOLD_IOU_SCORES\n",
    "    iou_scores_best = tf.reduce_max(iou_scores, axis=4, keep_dims=True)\n",
    "    iou_mask = tf.cast(iou_scores_best > THRESHOLD_IOU_SCORES, tf.float32)\n",
    "    \n",
    "    \n",
    "    ## Loss\n",
    "    # object confidence loss (presence and absence)\n",
    "    loss_confidence = get_confidence_loss(labels[...,5:6], iou_mask, predictions_prob_obj)\n",
    "    \n",
    "    # classification loss\n",
    "    loss_classification = get_classification_loss(labels[...,5:6], labels[...,4], predictions_prob_class)\n",
    "    \n",
    "    # regression loss\n",
    "    predictions_bbox = tf.concat([predictions_yx, predictions_hw], axis=-1)\n",
    "    loss_regression = get_regression_loss(labels_bbox, predictions_bbox, labels[...,5:6])\n",
    "    \n",
    "    # total loss\n",
    "    loss = ( loss_confidence + loss_classification + loss_regression ) / tf.cast(tf.shape(labels)[0], tf.float32)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center2corner(predictions_yx, predictions_hw):\n",
    "    # predictions_yx = [GRID_H, GRID_W, NUM_ANCHORS, 2]\n",
    "    \n",
    "    bbox_min = predictions_yx - (predictions_hw/2.)\n",
    "    bbox_max = predictions_yx + (predictions_hw/2.)\n",
    "    \n",
    "    predictions_corner = tf.concat([bbox_min[...,0:1], bbox_min[...,1:2], bbox_max[...,0:1], bbox_max[...,1:2]], axis=-1)\n",
    "    return predictions_corner\n",
    "\n",
    "def get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class):\n",
    "    # compute overall prob for each anchor in each grid\n",
    "    predictions_prob = predictions_prob_obj * predictions_prob_class\n",
    "    \n",
    "    # get max prob among all classes at each anchor in each grid\n",
    "    predictions_idx_class_max = tf.argmax(predictions_prob, axis=-1)\n",
    "    predictions_prob = tf.reduce_max(predictions_prob, axis=-1)\n",
    "    \n",
    "    # compute filter mask\n",
    "    mask_filter = predictions_prob >= THRESHOLD_OUT_PROB\n",
    "    \n",
    "    # apply mask on output\n",
    "    bbox_filtered = tf.boolean_mask(predictions_corner, mask_filter)\n",
    "    prob_filtered = tf.boolean_mask(predictions_prob, mask_filter)\n",
    "    idx_class_filtered = tf.boolean_mask(predictions_idx_class_max, mask_filter)\n",
    "    \n",
    "    return bbox_filtered, prob_filtered, idx_class_filtered\n",
    "\n",
    "\n",
    "def predictions2outputs(predictions):\n",
    "    # apply corresponding transformations on predictions\n",
    "    predictions_yx, predictions_hw, predictions_prob_obj, predictions_prob_class = apply_transformations(predictions)\n",
    "    \n",
    "    # map predictions_bbox to [0,1] space\n",
    "    predictions_yx, predictions_hw = grid2normalized(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # represent boxes using corners\n",
    "    predictions_corner = center2corner(predictions_yx, predictions_hw)\n",
    "    \n",
    "    # filter predictions based on (prob_obj * prob_class). (needs to be done separately for each image in batch)\n",
    "    bbox_filtered, prob_filtered, idx_class_filtered = get_filtered_predictions(predictions_corner, predictions_prob_obj, predictions_prob_class)\n",
    "    # bbox_filtered.shape = [BATCH_SIZE, NUM_FILTERED, 4]\n",
    "    \n",
    "    # TODO: perform nms for each class separately\n",
    "    # scale boxes from [0,1] to image space\n",
    "    img_space = tf.reshape(tf.cast(tf.stack([IMG_H, IMG_W, IMG_H, IMG_W]), tf.float32), [1, 1, 4])\n",
    "    bbox_filtered = tf.reshape(bbox_filtered * img_space, [-1, 4])\n",
    "    \n",
    "    # perform non-max suppression\n",
    "    bbox_nms_indices = tf.image.non_max_suppression(bbox_filtered, tf.reshape(prob_filtered,[-1]), MAX_DETECTIONS_PER_IMAGE)\n",
    "    bbox_nms = tf.gather(bbox_filtered, bbox_nms_indices)\n",
    "    prob_nms = tf.expand_dims(tf.gather(prob_filtered, bbox_nms_indices), axis=-1)\n",
    "    idx_class_nms = tf.expand_dims(tf.cast(tf.gather(idx_class_filtered, bbox_nms_indices), tf.float32), axis=-1)\n",
    "    \n",
    "    # concat return data\n",
    "    output = tf.concat([bbox_nms, prob_nms, idx_class_nms], axis=-1)\n",
    "    \n",
    "    return tf.expand_dims(output, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    # dictionary as per saved TFRecord\n",
    "    keys_to_features = {\n",
    "        'img': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "        'label': tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "    }\n",
    "\n",
    "    # parse record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    # decode image\n",
    "    img = tf.decode_raw(parsed['img'], tf.uint8)\n",
    "    img = tf.cast(tf.reshape(img, [IMG_H, IMG_W, 3]), tf.float32)\n",
    "    img /= 255.  # normalize\n",
    "\n",
    "    # decode label\n",
    "    label = tf.decode_raw(parsed['label'], tf.float32)\n",
    "    label = tf.reshape(label, [GRID_H, GRID_W, NUM_ANCHORS, 6])\n",
    "\n",
    "    return {'img': img}, label\n",
    "\n",
    "def input_fn_train(data_file):    \n",
    "    # dataset processing\n",
    "    dataset = tf.data.TFRecordDataset(data_file)\n",
    "    \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    img, label = iterator.get_next()\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def input_fn_predict(data_file):    \n",
    "    # dataset processing\n",
    "    dataset = tf.data.TFRecordDataset(data_file)\n",
    "    \n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    img, label = iterator.get_next()\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def get_feature_columns():\n",
    "    img = tf.feature_column.numeric_column('img', dtype=tf.float32)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # input layer\n",
    "    features = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    imgs = tf.reshape(features, [-1, IMG_H, IMG_W, 3])\n",
    "    # imgs.shape = (BATCH_SIZE, 608, 608, 3)\n",
    "    \n",
    "    # YOLO Network\n",
    "    predictions = YOLO_net( imgs, mode == tf.estimator.ModeKeys.TRAIN )\n",
    "    # predictions.shape = (BATCH_SIZE, 19, 19, 5, 25)\n",
    "    \n",
    "#     # dense\n",
    "#     x = tf.image.resize_images(imgs, [64, 64])\n",
    "#     x = tf.layers.flatten(x)\n",
    "#     x = tf.layers.dense(x, 256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "#     x = tf.layers.dense(x, 256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "#     x = tf.layers.dense(x, 256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "#     x = tf.layers.dense(x, 256, activation=tf.nn.relu, kernel_initializer=tf.glorot_uniform_initializer())\n",
    "#     x = tf.layers.dense(x, GRID_H*GRID_W*NUM_ANCHORS*(5+NUM_OBJECTS))\n",
    "#     predictions = tf.reshape(x, [-1, GRID_H, GRID_W, NUM_ANCHORS, 5+NUM_OBJECTS])\n",
    "    \n",
    "#     # CNN\n",
    "#     with tf.name_scope('CNN'):\n",
    "#         x = tf.layers.conv2d(imgs, filters=8, kernel_size=5, activation=tf.nn.relu, padding='same')\n",
    "#         x = tf.layers.max_pooling2d(x, pool_size=4, strides=4)\n",
    "        \n",
    "#         # x.shape = (BATCH_SIZE, 152, 152, 8)\n",
    "\n",
    "#         x = tf.layers.conv2d(x, filters=64, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "#         x = tf.layers.max_pooling2d(x, pool_size=4, strides=4)\n",
    "#         # x.shape = (BATCH_SIZE, 38, 38, 64)\n",
    "\n",
    "#         x = tf.layers.conv2d(x, filters=125, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "#         x = tf.layers.max_pooling2d(x, pool_size=2, strides=2)\n",
    "#         # x.shape = (BATCH_SIZE, 19, 19, 125)\n",
    "\n",
    "#         predictions = tf.reshape(x, (-1, GRID_H, GRID_W, params['num_anchors'], 5+params['num_objects']))\n",
    "#         # output.shape = (BATCH_SIZE, 19, 19, 5, 25)\n",
    "    \n",
    "    ## PREDICT\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        outputs = predictions2outputs(predictions)\n",
    "        outputs_dict = {\n",
    "            'imgs': imgs,\n",
    "            'outputs': outputs\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=outputs_dict)\n",
    "    \n",
    "    # compute loss\n",
    "    with tf.name_scope('Loss'):\n",
    "        loss = get_loss(predictions, labels)\n",
    "    tf.summary.scalar('loss_summary', loss)\n",
    "    \n",
    "    ## EVALUATE\n",
    "#     # compute evaluation metrics\n",
    "#     mse = tf.metrics.mean_squared_error(labels=labels, predictions=predictions, name='mse_op')\n",
    "#     metrics = {'mse': mse}\n",
    "#     tf.summary.scalar('mse', mse[1])\n",
    "#     if mode == tf.estimator.ModeKeys.EVAL:\n",
    "#         return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    ## TRAIN\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature columns\n",
    "feature_columns = get_feature_columns()\n",
    "\n",
    "# training configuration\n",
    "run_config = tf.estimator.RunConfig().replace(keep_checkpoint_max=1, save_summary_steps=10)\n",
    "\n",
    "# define model\n",
    "model = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    params={\n",
    "        'feature_columns': feature_columns,\n",
    "        'num_anchors': ANCHORS.shape[0],\n",
    "        'num_objects': NUM_OBJECTS\n",
    "    },\n",
    "    model_dir=MODEL_DIR,\n",
    "    config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(input_fn=lambda: input_fn_train(DATA_TRAIN), steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: map_fn for get_get_filtered_predictions needs return elements to be padded\n",
    "BATCH_SIZE = 1\n",
    "predictions = model.predict(input_fn=lambda: input_fn_predict(DATA_TRAIN))\n",
    "\n",
    "idx = 40\n",
    "iteration = 0\n",
    "for p in predictions:\n",
    "    i, o = p['imgs'], p['outputs']\n",
    "    if iteration == idx:\n",
    "        break\n",
    "    iteration += 1\n",
    "\n",
    "img = draw_output(i, o)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
