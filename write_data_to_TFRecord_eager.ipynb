{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /misc/me/pratikm/virtualEnv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = 'data_small'\n",
    "DIR_INPUT = os.path.join(DIR_DATA, 'input')\n",
    "DIR_OUTPUT = os.path.join(DIR_DATA, 'output')\n",
    "OBJECT_LABELS = {\n",
    "    'tvmonitor': (0, 'Indoor'),\n",
    "    'aeroplane': (1, 'Vehicle'),\n",
    "    'bicycle': (2, 'Vehicle'),\n",
    "    'bird': (3, 'Animal'),\n",
    "    'boat': (4, 'Vehicle'),\n",
    "    'bottle': (5, 'Indoor'),\n",
    "    'bus': (6, 'Vehicle'),\n",
    "    'car': (7, 'Vehicle'),\n",
    "    'cat': (8, 'Animal'),\n",
    "    'chair': (9, 'Indoor'),\n",
    "    'cow': (10, 'Animal'),\n",
    "    'diningtable': (11, 'Indoor'),\n",
    "    'dog': (12, 'Animal'),\n",
    "    'horse': (13, 'Animal'),\n",
    "    'motorbike': (14, 'Vehicle'),\n",
    "    'person': (15, 'Person'),\n",
    "    'pottedplant': (16, 'Indoor'),\n",
    "    'sheep': (17, 'Animal'),\n",
    "    'sofa': (18, 'Indoor'),\n",
    "    'train': (19, 'Vehicle')\n",
    "}\n",
    "NUM_OBJECTS = 20\n",
    "DIM_OUTPUT_PER_GRID_PER_ANCHOR = 5 + NUM_OBJECTS\n",
    "\n",
    "# Reference: https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg#L242 \n",
    "GRID_H, GRID_W = 13, 13 \n",
    "GRID_SIZE = 416//GRID_H\n",
    "ANCHORS = np.array(\n",
    "    [\n",
    "        [0.09112895, 0.06958421],\n",
    "        [0.21102316, 0.16803947],\n",
    "        [0.42625895, 0.26609842],\n",
    "        [0.25476474, 0.49848   ],\n",
    "        [0.52668947, 0.59138947]\n",
    "    ]\n",
    ")\n",
    "NUM_ANCHORS = ANCHORS.shape[0]\n",
    "ANCHORS *= np.array([GRID_H, GRID_W])  # map from [0,1] space to [0,19] space\n",
    "IMG_OUT_H, IMG_OUT_W = GRID_H * GRID_SIZE, GRID_W * GRID_SIZE \n",
    "\n",
    "DIR_TFRECORDS = 'data_small_tfrecords'\n",
    "NUM_EXAMPLES_PER_TFRECORD = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    # Reference: This function has been modified from \n",
    "    # https://github.com/balancap/SSD-Tensorflow/blob/master/datasets/pascalvoc_to_tfrecords.py\n",
    "    \n",
    "    # read and process image\n",
    "    img_name = os.path.join(DIR_INPUT, filename + '.jpg')\n",
    "    img = cv2.imread(img_name)\n",
    "    img_in_h = img.shape[0]\n",
    "    img_in_w = img.shape[1]\n",
    "    img = cv2.resize(img, (IMG_OUT_W, IMG_OUT_H))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # read annotation\n",
    "    annotation_name = os.path.join(DIR_OUTPUT, filename + '.xml')\n",
    "    tree = ET.parse(annotation_name)\n",
    "    root = tree.getroot()\n",
    "    targets = []\n",
    "    for obj in root.findall('object'):\n",
    "        # read class label\n",
    "        label_text = obj.find('name').text\n",
    "        label = int(OBJECT_LABELS[label_text][0])\n",
    "        \n",
    "        # read bbox\n",
    "        bbox = obj.find('bndbox')\n",
    "        y_min = float(bbox.find('ymin').text)\n",
    "        x_min = float(bbox.find('xmin').text)\n",
    "        y_max = float(bbox.find('ymax').text)\n",
    "        x_max = float(bbox.find('xmax').text)\n",
    "        \n",
    "        # convert from corner coordinates to x_center, y_center, width, height\n",
    "        y_center, x_center = (y_min + y_max)/2., (x_min + x_max)/2.\n",
    "        bbox_h, bbox_w = y_max - y_min, x_max - x_min\n",
    "        \n",
    "        # normalize these values s.t. image goes from 0 to 1 (helps for arbitary size image size)\n",
    "        y_center /= img_in_h\n",
    "        x_center /= img_in_w\n",
    "        bbox_h /= img_in_h\n",
    "        bbox_w /= img_in_w\n",
    "\n",
    "        targets.append((y_center, x_center, bbox_h, bbox_w, label))\n",
    "    \n",
    "    return img, np.array(targets, dtype=np.float32)\n",
    "\n",
    "def get_iou(hw1, hw2):\n",
    "    # hw: (height, width)\n",
    "    # assumption: both boxes have same centers\n",
    "    \n",
    "    # get extremes of both boxes\n",
    "    hw1_max, hw2_max = hw1/2., hw2/2.\n",
    "    hw1_min, hw2_min = -hw1_max, -hw2_max\n",
    "    \n",
    "    # get intersection area\n",
    "    intersection_min = np.maximum(hw1_min, hw2_min)\n",
    "    intersection_max = np.minimum(hw1_max, hw2_max)\n",
    "    hw_intersection = np.maximum(intersection_max-intersection_min, 0.)\n",
    "    area_intersection = hw_intersection[0] * hw_intersection[1]\n",
    "    \n",
    "    # get union area\n",
    "    area_hw1 = hw1[0] * hw1[1]\n",
    "    area_hw2 = hw2[0] * hw2[1]\n",
    "    area_union = area_hw1 + area_hw2 - area_intersection\n",
    "    \n",
    "    iou = area_intersection / area_union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def targets2label(targets):\n",
    "    # initialize return data\n",
    "    label = np.zeros((GRID_H, GRID_W, NUM_ANCHORS, 6), dtype=np.float32)  # 6: [offset_y, offset_x, scale_h, scale_w, class_idx, prob_obj]\n",
    "    \n",
    "    # check for all targets\n",
    "    for target in targets:\n",
    "        target_class = target[4]\n",
    "        \n",
    "        # map bbox from [0,1] space to [0,19] space\n",
    "        bbox = target[0:4] * np.array([GRID_H, GRID_W, GRID_H, GRID_W])\n",
    "        \n",
    "        # get grid index for bbox center\n",
    "        idx_y = int(floor(bbox[0]))\n",
    "        idx_x = int(floor(bbox[1]))\n",
    "        \n",
    "        # find best anchor corresponding to bbox\n",
    "        iou_best, idx_anchor_best = 0., 0\n",
    "        for idx_anchor, anchor in enumerate(ANCHORS):\n",
    "            iou = get_iou(bbox[2:4], anchor)\n",
    "            if iou > iou_best:\n",
    "                iou_best = iou\n",
    "                idx_anchor_best = idx_anchor\n",
    "            \n",
    "        # update label\n",
    "        if iou_best > 0.:\n",
    "            label[idx_y, idx_x, idx_anchor_best] = np.array(\n",
    "                [\n",
    "                    bbox[0] - idx_y,  # offset of box_center from top-left corner of grid containing box_center\n",
    "                    bbox[1] - idx_x,\n",
    "                    bbox[2]/ANCHORS[idx_anchor_best,0], # scale of anchor box so as to fit the bbox\n",
    "                    bbox[3]/ANCHORS[idx_anchor_best,1],\n",
    "                    target_class,\n",
    "                    1.0  # prob_object (object is present with prob=1)\n",
    "                ], dtype=np.float32\n",
    "            )\n",
    "    return label\n",
    "        \n",
    "def get_processed_data(filename):\n",
    "    # read input and output\n",
    "    img, targets = read_data(filename)\n",
    "    # targets.shape = (num_objects, 5)\n",
    "    # 5 corresponds to (c_y, c_x, h, w, class_label)\n",
    "    \n",
    "    label = targets2label(targets)\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to TFRecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion functions (data to feature data types)\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def write_example_to_TFRecord(filename, writer):\n",
    "    # get processed data\n",
    "    img, label = get_processed_data(filename)\n",
    "    \n",
    "    # create example from this data\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'img': _bytes_feature(img.tostring()),\n",
    "                'label': _bytes_feature(label.tostring()) \n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "def write_data_to_TFRecord():        \n",
    "    # read filenames\n",
    "    filenames = sorted(os.listdir(DIR_INPUT))\n",
    "    filenames = [filename[:-4] for filename in filenames]  # trim extension    \n",
    "    \n",
    "    # write data into multiple TFRecord files\n",
    "    idx_tfrecord, idx_data = 0, 0\n",
    "    if not os.path.exists(DIR_TFRECORDS):\n",
    "        os.makedirs(DIR_TFRECORDS)\n",
    "    \n",
    "    while idx_data < len(filenames):\n",
    "        # new TFRecord file\n",
    "        filename_tfrecord = os.path.join(DIR_TFRECORDS, str(idx_tfrecord) + '.tfrecords')\n",
    "        with tf.python_io.TFRecordWriter(filename_tfrecord) as writer:\n",
    "            # write examples into this file until limit is reached\n",
    "            idx_example = 0\n",
    "            while idx_data < len(filenames) and idx_example < NUM_EXAMPLES_PER_TFRECORD:\n",
    "                filename = filenames[idx_data]\n",
    "                write_example_to_TFRecord(filename, writer)\n",
    "                idx_data += 1\n",
    "                idx_example += 1\n",
    "            idx_tfrecord += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_to_TFRecord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
